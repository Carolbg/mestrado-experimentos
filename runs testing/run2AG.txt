tp, tour, tr, numberIterations, tm, isNumpy 10 2 80 10 20 True
isNumpy True
Load dataset
Lidando com numpy data
shuffleSeed 1
n_epochs 30 max_epochs_stop 10
device =  cpu

PrepareDataFromNumpy arrays
getFilesName
Imagens_numpy_array_allData_entireDatabase_MinMax_extrapolandoLimites
readFilesByPatient saudaveis
readFilesByPatient doentes

Split Healthy Dataset
Total dados 38
Quantidade de dados para treinamento 26
Quantidade de dados para teste 6
Quantidade de dados para validacao 6
trainPatients ['T0189', 'T0196', 'T0193', 'T0220', 'T0199', 'T0217', 'T0188', 'T0224', 'T0216', 'T0211', 'T0259', 'T0194', 'T0200', 'T0239', 'T0236', 'T0272', 'T0201', 'T0226', 'T0195', 'T0221', 'T0238', 'T0237', 'T0234', 'T0275', 'T0222', 'T0261']
validationPatients ['T0243', 'T0276', 'T0191', 'T0219', 'T0244', 'T0212']
testPatients ['T0218', 'T0233', 'T0208', 'T0190', 'T0225', 'T0177']
imagens do trainDataset 128
imagens do testDataset 30
imagens do validationDataset 30
train (128, 3, 224, 224)
test (30, 3, 224, 224)
validation (30, 3, 224, 224)

Split Cancer Dataset
Total dados 38
Quantidade de dados para treinamento 26
Quantidade de dados para teste 6
Quantidade de dados para validacao 6
trainPatients ['T0267', 'T0255', 'T0138', 'T0286', 'T0198', 'T0246', 'T0192', 'T0258', 'T0202', 'T0209', 'T0241', 'T0179', 'T0287', 'T0213', 'T0203', 'T0210', 'T0240', 'T0270', 'T0180', 'T0264', 'T0269', 'T0282', 'T0281', 'T0277', 'T0273', 'T0256']
validationPatients ['T0266', 'T0245', 'T0263', 'T0260', 'T0181', 'T0204']
testPatients ['T0257', 'T0278', 'T0285', 'T0268', 'T0283', 'T0271']
imagens do trainDataset 129
imagens do testDataset 29
imagens do validationDataset 30
train (129, 3, 224, 224)
test (29, 3, 224, 224)
validation (30, 3, 224, 224)

Total de dados para treinamento 257

Total de dados para teste 59

Total de dados para validacao 60
prepareNumpyDatasetBalancedData
Sem aumento de dados
com testValidationTransform Compose(
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
   category  Treinamento  Validação  Teste
0  Saudável          128         30     30
1    Doente          129         30     29


@@@@ Init pop
value =  4
value =  3
value =  4
value =  2
value =  5
value =  4
value =  4
value =  2
value =  2
value =  1
value =  3
value =  5
value =  2
value =  6
value =  1
value =  4
value =  1
value =  4
value =  1
value =  6


@@@@ Calculando fitness
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=4096, bias=True)
  (8): ReLU()
  (9): Linear(in_features=4096, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.70 and acc: 43.33%
2952.50 total seconds elapsed. 147.63 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.517510             0.627907  ...            0.000000    0.701414
1    0.548638             0.472868  ...            0.325581    0.700017
2    0.665370             0.674419  ...            0.171429    0.870218
3    0.688716             0.573643  ...            0.597403    0.974159
4    0.723735             0.674419  ...            0.552632    1.035678
5    0.712062             0.689922  ...            0.461538    0.930627
6    0.692607             0.612403  ...            0.474576    0.898861
7    0.774319             0.751938  ...            0.492754    1.102973
8    0.657588             0.728682  ...            0.626506    0.830222
9    0.782101             0.782946  ...            0.626506    1.129286
10   0.758755             0.790698  ...            0.454545    1.043129
11   0.785992             0.767442  ...            0.451613    1.201484
12   0.785992             0.821705  ...            0.507042    1.129601
13   0.754864             0.821705  ...            0.339623    1.120837
14   0.727626             0.689922  ...            0.400000    0.932925
15   0.840467             0.844961  ...            0.461538    1.279627
16   0.774319             0.844961  ...            0.492754    1.010523
17   0.813230             0.736434  ...            0.500000    1.215444
18   0.785992             0.837209  ...            0.459016    1.206939
19   0.840467             0.798450  ...            0.484848    1.278999

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.847458            0.862069             0.833333      0.847458
TestLoader Losses 0.4138723616882906
@@@@ individuo =  1 [list([4]) list([2]) list([1, 5]) list([0, 0.4725973393754025])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.847457627118644
verifyEntry ([4], [3], [1, 5], [1, 0.1262070664185572], [1, 5])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.1262070664185572, inplace=False)
  (3): Linear(in_features=32, out_features=32, bias=True)
  (4): ReLU()
  (5): Linear(in_features=32, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 43.33%
4197.55 total seconds elapsed. 139.92 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.494163             0.000000  ...            0.000000    0.694265
1    0.529183             0.612403  ...            0.157895    0.691588
2    0.536965             0.364341  ...            0.114286    0.694354
3    0.649805             0.426357  ...            0.641026    0.699422
4    0.614786             0.961240  ...            0.625000    0.709364
5    0.653696             0.581395  ...            0.529412    0.710861
6    0.657588             0.759690  ...            0.484848    0.720106
7    0.665370             0.627907  ...            0.631579    0.730329
8    0.680934             0.651163  ...            0.571429    0.734018
9    0.700389             0.689922  ...            0.461538    0.740683
10   0.696498             0.720930  ...            0.426230    0.744670
11   0.731518             0.744186  ...            0.500000    0.759119
12   0.739300             0.720930  ...            0.594595    0.779591
13   0.739300             0.751938  ...            0.419355    0.772520
14   0.723735             0.806202  ...            0.385965    0.781351
15   0.692607             0.604651  ...            0.623377    0.809076
16   0.758755             0.759690  ...            0.313725    0.805016
17   0.766537             0.736434  ...            0.477612    0.808030
18   0.743191             0.728682  ...            0.461538    0.809989
19   0.754864             0.713178  ...            0.521739    0.833765
20   0.793774             0.829457  ...            0.542857    0.849904
21   0.712062             0.666667  ...            0.555556    0.863091
22   0.758755             0.689922  ...            0.555556    0.871451
23   0.793774             0.899225  ...            0.476190    0.843551
24   0.824903             0.806202  ...            0.461538    0.872874
25   0.758755             0.790698  ...            0.433333    0.865289
26   0.750973             0.720930  ...            0.500000    0.890534
27   0.797665             0.837209  ...            0.521739    0.922718
28   0.782101             0.813953  ...            0.363636    0.906094
29   0.801556             0.821705  ...            0.484848    0.922652

[30 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0   0.79661            0.827586             0.766667           0.8
TestLoader Losses 0.4998544808161461
@@@@ individuo =  0 [list([4]) list([3]) list([0, 6]) list([0, 0.11110809481675672])
 list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
 list([1, 0.32935920000024327]) list([0, 3])
 list([0, 0.08762177840934646]) list([1, 5]) list([0, 0.1707647372757929])] 
 fitness =  0.7966101694915254
verifyEntry ([3], [5], [1, 8], [1, 10])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=256, bias=True)
  (1): ReLU()
  (2): Linear(in_features=256, out_features=1024, bias=True)
  (3): ReLU()
  (4): Linear(in_features=1024, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.78 and acc: 41.67%
6217.77 total seconds elapsed. 124.36 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.579767             0.658915  ...            0.000000    0.839841
1    0.642023             0.612403  ...            0.400000    0.781967
2    0.688716             0.689922  ...            0.222222    0.823647
3    0.735409             0.744186  ...            0.547945    1.029040
4    0.735409             0.728682  ...            0.563380    1.011941
5    0.793774             0.852713  ...            0.307692    1.086715
6    0.758755             0.775194  ...            0.558824    1.001801
7    0.735409             0.782946  ...            0.339623    0.890200
8    0.797665             0.821705  ...            0.250000    1.347082
9    0.692607             0.666667  ...            0.560000    0.933397
10   0.762646             0.767442  ...            0.659091    1.276454
11   0.758755             0.782946  ...            0.607595    1.075749
12   0.754864             0.790698  ...            0.470588    1.229543
13   0.805447             0.844961  ...            0.440678    1.167622
14   0.805447             0.829457  ...            0.448276    1.122656
15   0.809339             0.806202  ...            0.492308    1.017623
16   0.828794             0.844961  ...            0.529412    1.247650
17   0.852140             0.875969  ...            0.625000    1.465762
18   0.774319             0.767442  ...            0.433333    1.134556
19   0.817121             0.891473  ...            0.421053    1.186097
20   0.859922             0.829457  ...            0.500000    1.378000
21   0.774319             0.759690  ...            0.440678    1.301885
22   0.828794             0.844961  ...            0.567568    1.321767
23   0.836576             0.922481  ...            0.527778    1.313193
24   0.875486             0.844961  ...            0.461538    1.331992
25   0.879377             0.891473  ...            0.507042    1.387807
26   0.887160             0.868217  ...            0.392857    1.533759
27   0.797665             0.821705  ...            0.451613    1.265832
28   0.902724             0.883721  ...            0.492754    1.695606
29   0.828794             0.829457  ...            0.461538    1.388541
30   0.871595             0.875969  ...            0.567568    1.750707
31   0.906615             0.937984  ...            0.440678    1.576580
32   0.891051             0.906977  ...            0.466667    1.661916
33   0.832685             0.868217  ...            0.352941    1.688292
34   0.813230             0.782946  ...            0.560000    1.385689
35   0.871595             0.899225  ...            0.255319    1.487912
36   0.883268             0.868217  ...            0.500000    1.776670
37   0.867704             0.899225  ...            0.440678    1.300552
38   0.922179             0.930233  ...            0.483871    1.844057
39   0.891051             0.914729  ...            0.280000    2.030273
40   0.817121             0.798450  ...            0.468750    0.999600
41   0.891051             0.899225  ...            0.244898    1.832667
42   0.824903             0.798450  ...            0.540541    1.517461
43   0.852140             0.906977  ...            0.483871    1.561464
44   0.906615             0.922481  ...            0.413793    1.653861
45   0.875486             0.875969  ...            0.477612    1.559515
46   0.836576             0.860465  ...            0.483871    1.467012
47   0.875486             0.883721  ...            0.459016    1.599138
48   0.910506             0.922481  ...            0.484848    1.733372
49   0.894942             0.891473  ...            0.492754    1.863828

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.745763            0.965517             0.533333      0.788732
TestLoader Losses 0.6309780725988291
@@@@ individuo =  5 [list([3]) list([5]) list([0, 7]) list([1, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([0, 0.5465119394359016]) list([1, 8]) list([0, 0.556542328173652])
 list([1, 10]) list([0, 0.22107506160612872])] 
 fitness =  0.7457627118644068
verifyEntry ([4], [2], [1, 3], [1, 4], [1, 4])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=8, bias=True)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=16, bias=True)
  (3): ReLU()
  (4): Linear(in_features=16, out_features=16, bias=True)
  (5): ReLU()
  (6): Linear(in_features=16, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 46.67%
2883.03 total seconds elapsed. 144.15 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.486381             0.046512  ...            0.311111    0.693888
1    0.505837             0.108527  ...            0.377358    0.693103
2    0.564202             0.232558  ...            0.350877    0.694006
3    0.630350             0.348837  ...            0.173913    0.695348
4    0.696498             0.713178  ...            0.379310    0.695876
5    0.669261             0.488372  ...            0.632911    0.696246
6    0.649805             0.713178  ...            0.492308    0.698087
7    0.673152             0.945736  ...            0.321429    0.699760
8    0.715953             0.635659  ...            0.484848    0.701768
9    0.750973             0.899225  ...            0.650000    0.704360
10   0.735409             0.968992  ...            0.594595    0.708987
11   0.754864             0.844961  ...            0.650000    0.712042
12   0.778210             0.852713  ...            0.641975    0.716871
13   0.665370             0.837209  ...            0.476190    0.714045
14   0.739300             0.868217  ...            0.555556    0.718737
15   0.758755             0.821705  ...            0.641026    0.726869
16   0.719844             0.713178  ...            0.650000    0.731841
17   0.634241             0.844961  ...            0.483871    0.723417
18   0.793774             0.844961  ...            0.605263    0.740687
19   0.821012             0.922481  ...            0.555556    0.745330

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.728814            0.896552             0.566667      0.764706
TestLoader Losses 0.6186258550417625
@@@@ individuo =  3 [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
 list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
 list([1, 0.2574753409377971]) list([1, 4]) list([0, 0.25027141396285474])
 list([1, 4]) list([0, 0.3278614521834228])] 
 fitness =  0.7288135593220338
verifyEntry ([1], [6], [1, 5], [1, 7], [1, 0.06254698615663809])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=128, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.06254698615663809, inplace=False)
  (5): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 29 with loss: 0.69 and acc: 50.00%
5215.70 total seconds elapsed. 86.93 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.498054             0.589147  ...            0.666667    0.711929
1    0.513619             0.573643  ...            0.000000    0.714448
2    0.494163             0.480620  ...            0.666667    0.730953
3    0.486381             0.465116  ...            0.666667    0.697325
4    0.529183             0.759690  ...            0.000000    0.780203
5    0.478599             0.519380  ...            0.666667    0.693964
6    0.529183             0.705426  ...            0.000000    0.718791
7    0.501946             0.496124  ...            0.000000    0.735982
8    0.466926             0.232558  ...            0.666667    0.706803
9    0.459144             0.434109  ...            0.666667    0.708749
10   0.455253             0.612403  ...            0.000000    0.693764
11   0.474708             0.364341  ...            0.000000    0.694618
12   0.486381             0.209302  ...            0.666667    0.700855
13   0.505837             0.511628  ...            0.000000    0.694615
14   0.486381             0.751938  ...            0.666667    0.693197
15   0.463035             0.465116  ...            0.000000    0.696237
16   0.525292             0.286822  ...            0.666667    0.703932
17   0.525292             0.720930  ...            0.000000    0.699735
18   0.509728             0.310078  ...            0.666667    0.709928
19   0.482490             0.627907  ...            0.666667    0.693179
20   0.486381             0.410853  ...            0.000000    0.693159
21   0.447471             0.503876  ...            0.000000    0.693271
22   0.459144             0.372093  ...            0.666667    0.693486
23   0.505837             0.705426  ...            0.000000    0.702366
24   0.517510             0.511628  ...            0.666667    0.699220
25   0.533074             0.844961  ...            0.000000    0.696230
26   0.470817             0.542636  ...            0.666667    0.693154
27   0.505837             0.046512  ...            0.000000    0.693253
28   0.455253             0.565891  ...            0.666667    0.694799
29   0.463035             0.844961  ...            0.666667    0.693148
30   0.494163             0.767442  ...            0.000000    0.707012
31   0.509728             0.116279  ...            0.666667    0.698508
32   0.505837             0.666667  ...            0.000000    0.693622
33   0.451362             0.108527  ...            0.000000    0.693191
34   0.482490             0.713178  ...            0.000000    0.693411
35   0.474708             0.441860  ...            0.000000    0.701351
36   0.509728             0.581395  ...            0.666667    0.694822
37   0.443580             0.410853  ...            0.000000    0.693159
38   0.474708             0.403101  ...            0.000000    0.693161
39   0.478599             0.434109  ...            0.666667    0.693287
40   0.478599             0.317829  ...            0.666667    0.693665
41   0.513619             0.674419  ...            0.000000    0.703010
42   0.494163             0.565891  ...            0.666667    0.693477
43   0.490272             0.612403  ...            0.000000    0.695806
44   0.486381             0.868217  ...            0.000000    0.693170
45   0.494163             0.178295  ...            0.666667    0.696440
46   0.470817             0.387597  ...            0.666667    0.696625
47   0.474708             0.558140  ...            0.000000    0.693159
48   0.494163             0.410853  ...            0.666667    0.702535
49   0.490272             0.263566  ...            0.000000    0.693260
50   0.525292             0.209302  ...            0.666667    0.696238
51   0.501946             1.000000  ...            0.666667    0.693361
52   0.435798             0.713178  ...            0.000000    0.693450
53   0.509728             0.232558  ...            0.666667    0.696372
54   0.466926             0.472868  ...            0.000000    0.693497
55   0.490272             0.689922  ...            0.000000    0.701947
56   0.486381             0.519380  ...            0.666667    0.693249
57   0.494163             0.294574  ...            0.666667    0.710904
58   0.498054             0.620155  ...            0.000000    0.693659
59   0.505837             0.705426  ...            0.000000    0.706997

[60 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.508475                 0.0                  1.0           0.0
TestLoader Losses 0.7041691965976004
@@@@ individuo =  9 [list([1]) list([6]) list([1, 5]) list([0, 0.22913296920856388])
 list([0, 10]) list([1, 0.5830353897319063]) list([1, 7])
 list([1, 0.06254698615663809]) list([0, 12])
 list([0, 0.27847541914569013]) list([0, 6]) list([1, 0.0984059633528989])] 
 fitness =  0.5084745762711864
verifyEntry ([2], [6], [1, 8])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=256, bias=True)
  (1): ReLU()
  (2): Linear(in_features=256, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.73 and acc: 45.00%
6862.08 total seconds elapsed. 114.37 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.525292             0.589147  ...            0.139535    0.733861
1    0.610895             0.511628  ...            0.634146    0.875101
2    0.692607             0.682171  ...            0.550725    0.877727
3    0.715953             0.705426  ...            0.500000    0.881814
4    0.591440             0.658915  ...            0.114286    0.745642
5    0.653696             0.596899  ...            0.597403    0.823345
6    0.665370             0.736434  ...            0.064516    0.893333
7    0.684825             0.612403  ...            0.609756    1.010346
8    0.750973             0.759690  ...            0.444444    0.984321
9    0.747082             0.759690  ...            0.542857    1.193491
10   0.754864             0.736434  ...            0.461538    0.947303
11   0.832685             0.837209  ...            0.515152    1.309864
12   0.750973             0.775194  ...            0.421053    1.008558
13   0.684825             0.728682  ...            0.117647    0.887739
14   0.735409             0.651163  ...            0.594595    1.211351
15   0.789883             0.790698  ...            0.406780    1.529168
16   0.762646             0.767442  ...            0.582278    1.494587
17   0.863813             0.860465  ...            0.547945    1.433993
18   0.844358             0.844961  ...            0.492308    1.459366
19   0.856031             0.844961  ...            0.578947    1.538341
20   0.774319             0.821705  ...            0.529412    1.208661
21   0.852140             0.837209  ...            0.476190    1.292068
22   0.875486             0.852713  ...            0.421053    1.491096
23   0.836576             0.813953  ...            0.440678    1.440517
24   0.844358             0.844961  ...            0.492308    1.415498
25   0.856031             0.868217  ...            0.400000    1.456386
26   0.750973             0.744186  ...            0.571429    1.039369
27   0.848249             0.829457  ...            0.586667    1.615254
28   0.848249             0.875969  ...            0.523077    1.517617
29   0.891051             0.914729  ...            0.500000    1.732716
30   0.848249             0.844961  ...            0.153846    1.156231
31   0.856031             0.860465  ...            0.212766    1.679881
32   0.750973             0.798450  ...            0.619048    0.853743
33   0.891051             0.922481  ...            0.476190    1.677746
34   0.817121             0.821705  ...            0.585366    2.079965
35   0.844358             0.883721  ...            0.466667    1.367480
36   0.863813             0.875969  ...            0.571429    2.038706
37   0.762646             0.844961  ...            0.440678    0.856130
38   0.863813             0.953488  ...            0.560000    1.280930
39   0.828794             0.806202  ...            0.476190    1.059008
40   0.867704             0.899225  ...            0.492308    1.256085
41   0.879377             0.899225  ...            0.500000    1.959646
42   0.871595             0.844961  ...            0.492754    2.091466
43   0.910506             0.899225  ...            0.484848    1.875713
44   0.898833             0.891473  ...            0.476190    1.658856
45   0.875486             0.906977  ...            0.440678    1.446028
46   0.782101             0.713178  ...            0.484848    1.890109
47   0.824903             0.837209  ...            0.392857    1.508703
48   0.828794             0.821705  ...            0.643678    1.463434
49   0.840467             0.844961  ...            0.466667    1.002627
50   0.902724             0.906977  ...            0.461538    1.361330
51   0.902724             0.922481  ...            0.451613    1.523717
52   0.914397             0.930233  ...            0.212766    1.191555
53   0.891051             0.875969  ...            0.463768    2.050913
54   0.844358             0.798450  ...            0.459016    1.589716
55   0.859922             0.868217  ...            0.477612    1.796865
56   0.918288             0.883721  ...            0.521739    1.827468
57   0.887160             0.906977  ...            0.451613    1.658820
58   0.914397             0.906977  ...            0.563380    1.896219
59   0.914397             0.937984  ...            0.507463    1.767829

[60 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.779661            0.862069                  0.7      0.793651
TestLoader Losses 0.5654244594654795
@@@@ individuo =  6 [list([2]) list([6]) list([0, 9]) list([1, 0.22180133769376711])
 list([0, 4]) list([0, 0.5025231253900039]) list([0, 10])
 list([0, 0.30048912185595694]) list([0, 3]) list([1, 0.5778268747363061])
 list([1, 8]) list([0, 0.15174009389094614])] 
 fitness =  0.7796610169491526
verifyEntry ([2], [1], [1, 9], [1, 0.17065736910750998], [1, 11], [1, 0.3197351493711345], [1, 11], [1, 0.5177330618879615], [1, 9], [1, 3], [1, 0.27610931992185345])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=512, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.17065736910750998, inplace=False)
  (3): Linear(in_features=512, out_features=2048, bias=True)
  (4): ReLU()
  (5): Dropout(p=0.3197351493711345, inplace=False)
  (6): Linear(in_features=2048, out_features=2048, bias=True)
  (7): ReLU()
  (8): Dropout(p=0.5177330618879615, inplace=False)
  (9): Linear(in_features=2048, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=8, bias=True)
  (12): ReLU()
  (13): Dropout(p=0.27610931992185345, inplace=False)
  (14): Linear(in_features=8, out_features=2, bias=True)
)

Best epoch: 9 with loss: 0.69 and acc: 50.00%
1483.06 total seconds elapsed. 148.31 seconds per epoch.

Historico treinamento e validação 
    train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0   0.498054             0.372093  ...            0.000000    0.700819
1   0.498054             0.000000  ...            0.000000    0.696601
2   0.498054             0.000000  ...            0.000000    0.693664
3   0.498054             0.000000  ...            0.000000    0.693252
4   0.470817             0.271318  ...            0.666667    0.693151
5   0.501946             1.000000  ...            0.666667    0.693219
6   0.501946             1.000000  ...            0.666667    0.693203
7   0.501946             1.000000  ...            0.666667    0.693157
8   0.505837             0.085271  ...            0.000000    0.693158
9   0.451362             0.573643  ...            0.000000    0.693148

[10 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.508475                 0.0                  1.0           0.0
TestLoader Losses 0.6931247832411427
@@@@ individuo =  4 [list([2]) list([1]) list([1, 9]) list([1, 0.17065736910750998])
 list([1, 11]) list([1, 0.3197351493711345]) list([1, 11])
 list([1, 0.5177330618879615]) list([1, 9]) list([0, 0.21904405502555013])
 list([1, 3]) list([1, 0.27610931992185345])] 
 fitness =  0.5084745762711864
verifyEntry ([1], [4], [1, 4], [1, 0.5131789330011404])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=16, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.5131789330011404, inplace=False)
  (3): Linear(in_features=16, out_features=2, bias=True)
)

Best epoch: 32 with loss: 0.69 and acc: 50.00%
4727.37 total seconds elapsed. 118.18 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.494163             0.651163  ...            0.000000    0.704595
1    0.509728             0.348837  ...            0.666667    0.696609
2    0.494163             0.689922  ...            0.000000    0.693650
3    0.459144             0.697674  ...            0.000000    0.693678
4    0.517510             0.279070  ...            0.666667    0.703622
5    0.470817             0.542636  ...            0.666667    0.694067
6    0.490272             0.689922  ...            0.000000    0.694176
7    0.490272             0.689922  ...            0.000000    0.693380
8    0.478599             0.511628  ...            0.000000    0.693258
9    0.459144             0.426357  ...            0.000000    0.703813
10   0.494163             0.527132  ...            0.666667    0.694330
11   0.533074             0.294574  ...            0.666667    0.696313
12   0.529183             0.922481  ...            0.000000    0.696631
13   0.494163             0.449612  ...            0.666667    0.693615
14   0.486381             0.325581  ...            0.666667    0.695378
15   0.447471             0.519380  ...            0.666667    0.699750
16   0.486381             0.480620  ...            0.666667    0.693821
17   0.505837             0.627907  ...            0.000000    0.695468
18   0.494163             0.682171  ...            0.666667    0.693206
19   0.509728             0.232558  ...            0.666667    0.704947
20   0.529183             0.767442  ...            0.000000    0.711746
21   0.517510             0.472868  ...            0.666667    0.703834
22   0.501946             0.418605  ...            0.666667    0.695773
23   0.544747             0.705426  ...            0.000000    0.703421
24   0.478599             0.472868  ...            0.666667    0.693366
25   0.501946             0.457364  ...            0.666667    0.697127
26   0.494163             0.178295  ...            0.666667    0.695101
27   0.498054             0.891473  ...            0.000000    0.693742
28   0.474708             0.403101  ...            0.000000    0.696239
29   0.459144             0.658915  ...            0.000000    0.720498
30   0.525292             0.248062  ...            0.666667    0.706935
31   0.439689             0.472868  ...            0.666667    0.696184
32   0.474708             0.441860  ...            0.666667    0.693164
33   0.513619             0.984496  ...            0.000000    0.696420
34   0.486381             0.248062  ...            0.666667    0.695992
35   0.490272             0.379845  ...            0.000000    0.693290
36   0.513619             0.713178  ...            0.000000    0.705764
37   0.470817             0.581395  ...            0.666667    0.693520
38   0.470817             0.155039  ...            0.666667    0.693574
39   0.501946             1.000000  ...            0.666667    0.693188

[40 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.491525                 1.0                  0.0      0.659091
TestLoader Losses 0.6933418037527699
@@@@ individuo =  8 [list([1]) list([4]) list([0, 12]) list([1, 0.5006134136469155])
 list([1, 4]) list([1, 0.5131789330011404]) list([0, 5])
 list([0, 0.09388172525141285]) list([0, 10])
 list([1, 0.22219944131625358]) list([0, 5]) list([1, 0.2114601169312868])] 
 fitness =  0.4915254237288136
verifyEntry ([5], [4], [1, 7], [1, 0.12676812206472354])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.12676812206472354, inplace=False)
  (3): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.70 and acc: 40.00%
5347.25 total seconds elapsed. 133.68 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.443580             0.426357  ...            0.609756    0.696995
1    0.494163             0.248062  ...            0.468750    0.698817
2    0.591440             0.534884  ...            0.400000    0.708752
3    0.568093             0.558140  ...            0.454545    0.714726
4    0.669261             0.720930  ...            0.507042    0.715873
5    0.653696             0.705426  ...            0.424242    0.717600
6    0.614786             0.627907  ...            0.357143    0.717051
7    0.680934             0.689922  ...            0.424242    0.721631
8    0.727626             0.612403  ...            0.338983    0.722026
9    0.708171             0.651163  ...            0.424242    0.722624
10   0.704280             0.674419  ...            0.447761    0.724766
11   0.735409             0.782946  ...            0.485714    0.725489
12   0.743191             0.860465  ...            0.470588    0.730353
13   0.712062             0.658915  ...            0.380952    0.731914
14   0.719844             0.759690  ...            0.547945    0.735055
15   0.673152             0.573643  ...            0.454545    0.735159
16   0.735409             0.798450  ...            0.535211    0.738390
17   0.719844             0.806202  ...            0.492754    0.737140
18   0.715953             0.651163  ...            0.447761    0.742463
19   0.743191             0.813953  ...            0.535211    0.745806
20   0.684825             0.589147  ...            0.492754    0.743042
21   0.735409             0.821705  ...            0.492754    0.746653
22   0.731518             0.720930  ...            0.514286    0.751747
23   0.743191             0.705426  ...            0.555556    0.751316
24   0.712062             0.720930  ...            0.470588    0.755460
25   0.758755             0.806202  ...            0.555556    0.760585
26   0.750973             0.705426  ...            0.447761    0.761543
27   0.712062             0.813953  ...            0.555556    0.766492
28   0.731518             0.635659  ...            0.470588    0.762625
29   0.735409             0.782946  ...            0.555556    0.773405
30   0.735409             0.782946  ...            0.535211    0.773799
31   0.735409             0.713178  ...            0.400000    0.776139
32   0.739300             0.775194  ...            0.555556    0.778083
33   0.723735             0.674419  ...            0.470588    0.776542
34   0.735409             0.736434  ...            0.492754    0.775897
35   0.754864             0.829457  ...            0.575342    0.792923
36   0.719844             0.689922  ...            0.447761    0.780952
37   0.778210             0.829457  ...            0.555556    0.794448
38   0.727626             0.682171  ...            0.514286    0.790675
39   0.754864             0.751938  ...            0.470588    0.784164

[40 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.779661            0.758621                  0.8       0.77193
TestLoader Losses 0.5734340245440855
@@@@ individuo =  2 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])] 
 fitness =  0.7796610169491526
verifyEntry ([1], [4], [1, 5], [1, 12])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=4096, bias=True)
  (3): ReLU()
  (4): Linear(in_features=4096, out_features=2, bias=True)
)

Best epoch: 13 with loss: 0.69 and acc: 50.00%
5348.63 total seconds elapsed. 133.72 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.486381             0.519380  ...            0.000000    2.343159
1    0.513619             0.511628  ...            0.666667    1.083950
2    0.490272             0.457364  ...            0.666667    0.828650
3    0.544747             0.542636  ...            0.666667    1.058665
4    0.509728             0.542636  ...            0.666667    2.708095
5    0.486381             0.457364  ...            0.666667    0.789936
6    0.474708             0.558140  ...            0.000000    3.508707
7    0.529183             0.418605  ...            0.666667    0.718627
8    0.509728             0.542636  ...            0.666667    2.063398
9    0.498054             0.465116  ...            0.000000    1.060166
10   0.470817             0.503876  ...            0.666667    0.743871
11   0.533074             0.527132  ...            0.000000    0.694653
12   0.517510             0.511628  ...            0.666667    1.686917
13   0.466926             0.511628  ...            0.000000    0.694089
14   0.494163             0.488372  ...            0.666667    0.746612
15   0.529183             0.534884  ...            0.000000    0.694375
16   0.560311             0.527132  ...            0.666667    0.727404
17   0.482490             0.527132  ...            0.666667    0.736483
18   0.501946             0.612403  ...            0.666667    0.850105
19   0.517510             0.550388  ...            0.666667    0.818694
20   0.490272             0.496124  ...            0.666667    0.724829
21   0.482490             0.410853  ...            0.666667    0.767528
22   0.459144             0.581395  ...            0.000000    0.770040
23   0.494163             0.565891  ...            0.666667    0.725824
24   0.509728             0.503876  ...            0.666667    0.861165
25   0.498054             0.503876  ...            0.666667    0.726624
26   0.517510             0.627907  ...            0.000000    1.020498
27   0.486381             0.441860  ...            0.666667    0.719957
28   0.509728             0.426357  ...            0.666667    0.954726
29   0.525292             0.558140  ...            0.000000    0.725509
30   0.494163             0.488372  ...            0.666667    0.695569
31   0.431907             0.348837  ...            0.666667    0.741892
32   0.509728             0.465116  ...            0.666667    0.707809
33   0.490272             0.457364  ...            0.666667    0.705955
34   0.455253             0.527132  ...            0.000000    0.695212
35   0.544747             0.550388  ...            0.000000    0.838612
36   0.552529             0.596899  ...            0.000000    0.892473
37   0.513619             0.480620  ...            0.000000    0.832629
38   0.536965             0.581395  ...            0.000000    0.729195
39   0.420233             0.387597  ...            0.000000    0.720902

[40 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.508475                 0.0                  1.0           0.0
TestLoader Losses 0.7169020034499087
@@@@ individuo =  7 [list([1]) list([4]) list([0, 5]) list([0, 0.5370564876829839])
 list([1, 5]) list([0, 0.18765050104451392]) list([0, 8])
 list([1, 0.560022378540593]) list([0, 10]) list([1, 0.21037022468185587])
 list([1, 12]) list([0, 0.41247977376500733])] 
 fitness =  0.5084745762711864
result (0, 0.7966101694915254)
result (1, 0.847457627118644)
result (2, 0.7796610169491526)
result (3, 0.7288135593220338)
result (4, 0.5084745762711864)
result (5, 0.7457627118644068)
result (6, 0.7796610169491526)
result (7, 0.5084745762711864)
result (8, 0.4915254237288136)
result (9, 0.5084745762711864)

individuo [list([4]) list([3]) list([0, 6]) list([0, 0.11110809481675672])
 list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
 list([1, 0.32935920000024327]) list([0, 3])
 list([0, 0.08762177840934646]) list([1, 5]) list([0, 0.1707647372757929])]  key  ([4], [3], [1, 5], [1, 0.1262070664185572], [1, 5]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.4725973393754025])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12]) 


individuo [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])]  key  ([5], [4], [1, 7], [1, 0.12676812206472354]) 


individuo [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
 list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
 list([1, 0.2574753409377971]) list([1, 4]) list([0, 0.25027141396285474])
 list([1, 4]) list([0, 0.3278614521834228])]  key  ([4], [2], [1, 3], [1, 4], [1, 4]) 


individuo [list([2]) list([1]) list([1, 9]) list([1, 0.17065736910750998])
 list([1, 11]) list([1, 0.3197351493711345]) list([1, 11])
 list([1, 0.5177330618879615]) list([1, 9]) list([0, 0.21904405502555013])
 list([1, 3]) list([1, 0.27610931992185345])]  key  ([2], [1], [1, 9], [1, 0.17065736910750998], [1, 11], [1, 0.3197351493711345], [1, 11], [1, 0.5177330618879615], [1, 9], [1, 3], [1, 0.27610931992185345]) 


individuo [list([3]) list([5]) list([0, 7]) list([1, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([0, 0.5465119394359016]) list([1, 8]) list([0, 0.556542328173652])
 list([1, 10]) list([0, 0.22107506160612872])]  key  ([3], [5], [1, 8], [1, 10]) 


individuo [list([2]) list([6]) list([0, 9]) list([1, 0.22180133769376711])
 list([0, 4]) list([0, 0.5025231253900039]) list([0, 10])
 list([0, 0.30048912185595694]) list([0, 3]) list([1, 0.5778268747363061])
 list([1, 8]) list([0, 0.15174009389094614])]  key  ([2], [6], [1, 8]) 


individuo [list([1]) list([4]) list([0, 5]) list([0, 0.5370564876829839])
 list([1, 5]) list([0, 0.18765050104451392]) list([0, 8])
 list([1, 0.560022378540593]) list([0, 10]) list([1, 0.21037022468185587])
 list([1, 12]) list([0, 0.41247977376500733])]  key  ([1], [4], [1, 5], [1, 12]) 


individuo [list([1]) list([4]) list([0, 12]) list([1, 0.5006134136469155])
 list([1, 4]) list([1, 0.5131789330011404]) list([0, 5])
 list([0, 0.09388172525141285]) list([0, 10])
 list([1, 0.22219944131625358]) list([0, 5]) list([1, 0.2114601169312868])]  key  ([1], [4], [1, 4], [1, 0.5131789330011404]) 


individuo [list([1]) list([6]) list([1, 5]) list([0, 0.22913296920856388])
 list([0, 10]) list([1, 0.5830353897319063]) list([1, 7])
 list([1, 0.06254698615663809]) list([0, 12])
 list([0, 0.27847541914569013]) list([0, 6]) list([1, 0.0984059633528989])]  key  ([1], [6], [1, 5], [1, 7], [1, 0.06254698615663809]) 


cacheStore =  {'([4], [3], [1, 5], [1, 0.1262070664185572], [1, 5])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.847457627118644, '([5], [4], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [2], [1, 3], [1, 4], [1, 4])': 0.7288135593220338, '([2], [1], [1, 9], [1, 0.17065736910750998], [1, 11], [1, 0.3197351493711345], [1, 11], [1, 0.5177330618879615], [1, 9], [1, 3], [1, 0.27610931992185345])': 0.5084745762711864, '([3], [5], [1, 8], [1, 10])': 0.7457627118644068, '([2], [6], [1, 8])': 0.7796610169491526, '([1], [4], [1, 5], [1, 12])': 0.5084745762711864, '([1], [4], [1, 4], [1, 0.5131789330011404])': 0.4915254237288136, '([1], [6], [1, 5], [1, 7], [1, 0.06254698615663809])': 0.5084745762711864}


 $$$$$$$$ Geração  0
population =  [[list([4]) list([3]) list([0, 6]) list([0, 0.11110809481675672])
  list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
  list([1, 0.32935920000024327]) list([0, 3])
  list([0, 0.08762177840934646]) list([1, 5])
  list([0, 0.1707647372757929])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.4725973393754025])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
  list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.12676812206472354])]
 [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
  list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
  list([1, 0.2574753409377971]) list([1, 4])
  list([0, 0.25027141396285474]) list([1, 4])
  list([0, 0.3278614521834228])]
 [list([2]) list([1]) list([1, 9]) list([1, 0.17065736910750998])
  list([1, 11]) list([1, 0.3197351493711345]) list([1, 11])
  list([1, 0.5177330618879615]) list([1, 9])
  list([0, 0.21904405502555013]) list([1, 3])
  list([1, 0.27610931992185345])]
 [list([3]) list([5]) list([0, 7]) list([1, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([0, 0.5465119394359016]) list([1, 8]) list([0, 0.556542328173652])
  list([1, 10]) list([0, 0.22107506160612872])]
 [list([2]) list([6]) list([0, 9]) list([1, 0.22180133769376711])
  list([0, 4]) list([0, 0.5025231253900039]) list([0, 10])
  list([0, 0.30048912185595694]) list([0, 3])
  list([1, 0.5778268747363061]) list([1, 8])
  list([0, 0.15174009389094614])]
 [list([1]) list([4]) list([0, 5]) list([0, 0.5370564876829839])
  list([1, 5]) list([0, 0.18765050104451392]) list([0, 8])
  list([1, 0.560022378540593]) list([0, 10])
  list([1, 0.21037022468185587]) list([1, 12])
  list([0, 0.41247977376500733])]
 [list([1]) list([4]) list([0, 12]) list([1, 0.5006134136469155])
  list([1, 4]) list([1, 0.5131789330011404]) list([0, 5])
  list([0, 0.09388172525141285]) list([0, 10])
  list([1, 0.22219944131625358]) list([0, 5])
  list([1, 0.2114601169312868])]
 [list([1]) list([6]) list([1, 5]) list([0, 0.22913296920856388])
  list([0, 10]) list([1, 0.5830353897319063]) list([1, 7])
  list([1, 0.06254698615663809]) list([0, 12])
  list([0, 0.27847541914569013]) list([0, 6])
  list([1, 0.0984059633528989])]]
populationFitness =  [0.79661017 0.84745763 0.77966102 0.72881356 0.50847458 0.74576271
 0.77966102 0.50847458 0.49152542 0.50847458]
bestParent, bestParentFitness [list([4]) list([2]) list([1, 5]) list([0, 0.4725973393754025])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 0.847457627118644


@@@@ Selecao
indexParent 2
indexParent 2
indexParent 3
indexParent 1
indexParent 5
indexParent 2
indexParent 0
indexParent 3
indexParent 2
indexParent 5


@@@@ Crossover
not changing individuals
crossoverPoint 7
crossoverPoint 8
crossoverPoint 7
crossoverPoint 4


@@@@ Mutacao
Individuos para mutacao [4, 2]
@@@ mutated [1, 0.5465119394359016]
@@@ mutated [0, 0.09768904831161847]


@@@@ Calculando fitness
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.2574753409377971], [1, 4], [1, 4])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Dropout(p=0.2574753409377971, inplace=False)
  (8): Linear(in_features=2048, out_features=16, bias=True)
  (9): ReLU()
  (10): Linear(in_features=16, out_features=16, bias=True)
  (11): ReLU()
  (12): Linear(in_features=16, out_features=2, bias=True)
)

Best epoch: 3 with loss: 0.69 and acc: 48.33%
3246.89 total seconds elapsed. 162.34 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.501946             1.000000  ...            0.666667    0.703528
1    0.501946             1.000000  ...            0.666667    0.699681
2    0.501946             1.000000  ...            0.666667    0.694824
3    0.505837             0.612403  ...            0.062500    0.692523
4    0.556420             0.434109  ...            0.632911    0.694143
5    0.680934             0.620155  ...            0.352941    0.701658
6    0.700389             0.589147  ...            0.613333    0.715280
7    0.677043             0.581395  ...            0.413793    0.751360
8    0.743191             0.720930  ...            0.426230    0.809300
9    0.743191             0.713178  ...            0.521739    0.861897
10   0.774319             0.844961  ...            0.484848    0.919775
11   0.778210             0.798450  ...            0.406780    0.995665
12   0.774319             0.813953  ...            0.468750    1.008971
13   0.708171             0.736434  ...            0.537313    0.986212
14   0.754864             0.759690  ...            0.419355    1.004268
15   0.731518             0.720930  ...            0.297872    1.040541
16   0.789883             0.837209  ...            0.492308    0.994664
17   0.813230             0.837209  ...            0.468750    1.043439
18   0.809339             0.806202  ...            0.507463    1.096307
19   0.750973             0.798450  ...            0.607595    1.141940

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.644068            0.965517             0.333333      0.727273
TestLoader Losses 0.595982430344921
@@@@ individuo =  6 [list([4]) list([2]) list([1, 5]) list([0, 0.4725973393754025])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([1, 0.2574753409377971]) list([1, 4]) list([0, 0.25027141396285474])
 list([1, 4]) list([0, 0.3278614521834228])] 
 fitness =  0.6440677966101694
verifyEntry ([5], [4], [1, 8], [1, 10])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=256, bias=True)
  (1): ReLU()
  (2): Linear(in_features=256, out_features=1024, bias=True)
  (3): ReLU()
  (4): Linear(in_features=1024, out_features=2, bias=True)
)

Best epoch: 2 with loss: 0.69 and acc: 45.00%
5166.67 total seconds elapsed. 129.17 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.513619             0.937984  ...            0.643678    0.694758
1    0.630350             0.813953  ...            0.625000    0.694019
2    0.673152             0.860465  ...            0.594595    0.693854
3    0.684825             0.550388  ...            0.448276    0.694893
4    0.680934             0.829457  ...            0.594595    0.697328
5    0.731518             0.844961  ...            0.521739    0.697084
6    0.739300             0.666667  ...            0.515152    0.697908
7    0.692607             0.604651  ...            0.550725    0.699405
8    0.723735             0.728682  ...            0.583333    0.703192
9    0.704280             0.666667  ...            0.523077    0.701040
10   0.747082             0.705426  ...            0.492308    0.705177
11   0.692607             0.503876  ...            0.433333    0.706010
12   0.735409             0.875969  ...            0.594595    0.714694
13   0.719844             0.759690  ...            0.400000    0.714167
14   0.758755             0.782946  ...            0.507463    0.714811
15   0.719844             0.728682  ...            0.515152    0.718698
16   0.739300             0.651163  ...            0.575342    0.723646
17   0.766537             0.798450  ...            0.583333    0.727907
18   0.762646             0.852713  ...            0.563380    0.735458
19   0.774319             0.736434  ...            0.521739    0.739672
20   0.785992             0.790698  ...            0.555556    0.750150
21   0.747082             0.829457  ...            0.468750    0.751052
22   0.754864             0.705426  ...            0.575342    0.758370
23   0.735409             0.813953  ...            0.555556    0.764093
24   0.758755             0.775194  ...            0.555556    0.775719
25   0.719844             0.829457  ...            0.385965    0.777638
26   0.747082             0.720930  ...            0.555556    0.781983
27   0.766537             0.775194  ...            0.521739    0.784093
28   0.797665             0.813953  ...            0.521739    0.797683
29   0.747082             0.736434  ...            0.542857    0.804303
30   0.801556             0.868217  ...            0.521739    0.824794
31   0.789883             0.813953  ...            0.477612    0.806612
32   0.782101             0.736434  ...            0.555556    0.845969
33   0.770428             0.844961  ...            0.477612    0.835685
34   0.766537             0.728682  ...            0.542857    0.850103
35   0.774319             0.852713  ...            0.542857    0.852696
36   0.801556             0.790698  ...            0.500000    0.842025
37   0.778210             0.798450  ...            0.575342    0.891378
38   0.809339             0.806202  ...            0.563380    0.886783
39   0.782101             0.767442  ...            0.535211    0.890494

[40 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.830508            0.931034             0.733333       0.84375
TestLoader Losses 0.49823177466958257
@@@@ individuo =  4 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([1, 8]) list([0, 0.556542328173652])
 list([1, 10]) list([0, 0.22107506160612872])] 
 fitness =  0.8305084745762712
verifyEntry ([4], [2], [1, 3], [1, 12])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=8, bias=True)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=4096, bias=True)
  (3): ReLU()
  (4): Linear(in_features=4096, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.70 and acc: 41.67%
3235.25 total seconds elapsed. 161.76 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.498054             0.666667  ...            0.000000    0.700559
1    0.579767             0.387597  ...            0.666667    0.699503
2    0.634241             0.418605  ...            0.666667    0.721693
3    0.591440             0.635659  ...            0.658537    0.739081
4    0.704280             0.790698  ...            0.240000    0.767331
5    0.704280             0.697674  ...            0.507937    0.805057
6    0.719844             0.658915  ...            0.650000    0.960545
7    0.727626             0.728682  ...            0.642857    1.128993
8    0.727626             0.775194  ...            0.515152    0.932466
9    0.747082             0.697674  ...            0.500000    0.947815
10   0.766537             0.759690  ...            0.631579    1.087259
11   0.774319             0.806202  ...            0.500000    1.041351
12   0.774319             0.806202  ...            0.426230    1.049029
13   0.813230             0.782946  ...            0.477612    1.125711
14   0.747082             0.790698  ...            0.461538    0.995936
15   0.809339             0.790698  ...            0.477612    1.087267
16   0.782101             0.813953  ...            0.301887    1.108193
17   0.758755             0.705426  ...            0.560000    1.205788
18   0.840467             0.883721  ...            0.477612    1.132063
19   0.863813             0.860465  ...            0.477612    1.161010

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0   0.79661            0.758621             0.833333      0.785714
TestLoader Losses 0.48717366992417027
@@@@ individuo =  1 [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
 list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7966101694915254
verifyEntry ([5], [4], [1, 8], [1, 10])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=256, bias=True)
  (1): ReLU()
  (2): Linear(in_features=256, out_features=1024, bias=True)
  (3): ReLU()
  (4): Linear(in_features=1024, out_features=2, bias=True)
)

Best epoch: 2 with loss: 0.69 and acc: 45.00%
5165.23 total seconds elapsed. 129.13 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.513619             0.937984  ...            0.643678    0.694758
1    0.630350             0.813953  ...            0.625000    0.694019
2    0.673152             0.860465  ...            0.594595    0.693854
3    0.684825             0.550388  ...            0.448276    0.694893
4    0.680934             0.829457  ...            0.594595    0.697328
5    0.731518             0.844961  ...            0.521739    0.697084
6    0.739300             0.666667  ...            0.515152    0.697908
7    0.692607             0.604651  ...            0.550725    0.699405
8    0.723735             0.728682  ...            0.583333    0.703192
9    0.704280             0.666667  ...            0.523077    0.701040
10   0.747082             0.705426  ...            0.492308    0.705177
11   0.692607             0.503876  ...            0.433333    0.706010
12   0.735409             0.875969  ...            0.594595    0.714694
13   0.719844             0.759690  ...            0.400000    0.714167
14   0.758755             0.782946  ...            0.507463    0.714811
15   0.719844             0.728682  ...            0.515152    0.718698
16   0.739300             0.651163  ...            0.575342    0.723646
17   0.766537             0.798450  ...            0.583333    0.727907
18   0.762646             0.852713  ...            0.563380    0.735458
19   0.774319             0.736434  ...            0.521739    0.739672
20   0.785992             0.790698  ...            0.555556    0.750150
21   0.747082             0.829457  ...            0.468750    0.751052
22   0.754864             0.705426  ...            0.575342    0.758370
23   0.735409             0.813953  ...            0.555556    0.764093
24   0.758755             0.775194  ...            0.555556    0.775719
25   0.719844             0.829457  ...            0.385965    0.777638
26   0.747082             0.720930  ...            0.555556    0.781983
27   0.766537             0.775194  ...            0.521739    0.784093
28   0.797665             0.813953  ...            0.521739    0.797683
29   0.747082             0.736434  ...            0.542857    0.804303
30   0.801556             0.868217  ...            0.521739    0.824794
31   0.789883             0.813953  ...            0.477612    0.806612
32   0.782101             0.736434  ...            0.555556    0.845969
33   0.770428             0.844961  ...            0.477612    0.835685
34   0.766537             0.728682  ...            0.542857    0.850103
35   0.774319             0.852713  ...            0.542857    0.852696
36   0.801556             0.790698  ...            0.500000    0.842025
37   0.778210             0.798450  ...            0.575342    0.891378
38   0.809339             0.806202  ...            0.563380    0.886783
39   0.782101             0.767442  ...            0.535211    0.890494

[40 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.830508            0.931034             0.733333       0.84375
TestLoader Losses 0.49823177466958257
@@@@ individuo =  7 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([1, 8]) list([0, 0.556542328173652])
 list([1, 10]) list([0, 0.22107506160612872])] 
 fitness =  0.8305084745762712
verifyEntry ([4], [3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.1262070664185572, inplace=False)
  (3): Linear(in_features=32, out_features=16, bias=True)
  (4): ReLU()
  (5): Linear(in_features=16, out_features=16, bias=True)
  (6): ReLU()
  (7): Linear(in_features=16, out_features=2, bias=True)
)

Best epoch: 3 with loss: 0.69 and acc: 45.00%
4286.45 total seconds elapsed. 142.88 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.501946             1.000000  ...            0.666667    0.694577
1    0.525292             0.922481  ...            0.666667    0.693816
2    0.521401             1.000000  ...            0.666667    0.693850
3    0.579767             0.635659  ...            0.551724    0.693638
4    0.607004             0.829457  ...            0.619718    0.694673
5    0.610895             0.558140  ...            0.634146    0.697345
6    0.610895             0.457364  ...            0.142857    0.699389
7    0.622568             0.465116  ...            0.377358    0.701155
8    0.634241             0.643411  ...            0.217391    0.702341
9    0.700389             0.573643  ...            0.377358    0.704555
10   0.657588             0.441860  ...            0.400000    0.707290
11   0.708171             0.620155  ...            0.370370    0.709449
12   0.669261             0.527132  ...            0.102564    0.713220
13   0.661479             0.511628  ...            0.385965    0.713934
14   0.743191             0.612403  ...            0.385965    0.715253
15   0.712062             0.565891  ...            0.484848    0.716095
16   0.696498             0.527132  ...            0.444444    0.719093
17   0.719844             0.643411  ...            0.326531    0.729783
18   0.704280             0.658915  ...            0.426230    0.726325
19   0.723735             0.635659  ...            0.377358    0.738817
20   0.719844             0.620155  ...            0.392857    0.735109
21   0.735409             0.573643  ...            0.521739    0.729808
22   0.778210             0.705426  ...            0.370370    0.755837
23   0.684825             0.573643  ...            0.555556    0.733766
24   0.754864             0.744186  ...            0.370370    0.757995
25   0.739300             0.658915  ...            0.500000    0.752230
26   0.766537             0.728682  ...            0.484848    0.766902
27   0.731518             0.651163  ...            0.476190    0.767914
28   0.797665             0.736434  ...            0.433333    0.779438
29   0.774319             0.720930  ...            0.521739    0.773791

[30 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.813559            0.862069             0.766667      0.819672
TestLoader Losses 0.5543175602363328
@@@@ individuo =  3 [list([4]) list([3]) list([0, 6]) list([0, 0.11110809481675672])
 list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
 list([1, 0.2574753409377971]) list([1, 4]) list([0, 0.25027141396285474])
 list([1, 4]) list([0, 0.3278614521834228])] 
 fitness =  0.8135593220338984
verifyEntry ([5], [4], [1, 7], [1, 0.12676812206472354])

achei cache 0.7796610169491526  individuo =  5 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])] 
 fitness =  0.7796610169491526
verifyEntry ([3], [5], [1, 7], [1, 0.12676812206472354])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.12676812206472354, inplace=False)
  (3): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.73 and acc: 46.67%
5812.74 total seconds elapsed. 116.25 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.536965             0.620155  ...            0.521739    0.727564
1    0.579767             0.527132  ...            0.062500    0.776678
2    0.630350             0.604651  ...            0.635294    0.815597
3    0.622568             0.682171  ...            0.344828    0.778898
4    0.723735             0.767442  ...            0.212766    0.830819
5    0.688716             0.651163  ...            0.514286    0.833353
6    0.715953             0.674419  ...            0.575342    0.890229
7    0.727626             0.775194  ...            0.421053    0.843507
8    0.778210             0.751938  ...            0.529412    0.889862
9    0.723735             0.751938  ...            0.421053    0.882700
10   0.801556             0.767442  ...            0.563380    0.984487
11   0.809339             0.821705  ...            0.346154    0.936369
12   0.774319             0.790698  ...            0.392857    0.965204
13   0.747082             0.759690  ...            0.500000    1.038549
14   0.782101             0.759690  ...            0.255319    0.987254
15   0.813230             0.829457  ...            0.529412    1.052404
16   0.848249             0.829457  ...            0.521739    1.126707
17   0.828794             0.829457  ...            0.552632    1.238134
18   0.805447             0.813953  ...            0.456140    1.036335
19   0.750973             0.751938  ...            0.602410    1.290989
20   0.754864             0.767442  ...            0.483871    0.999579
21   0.789883             0.759690  ...            0.602410    1.371739
22   0.793774             0.852713  ...            0.326531    1.108752
23   0.782101             0.759690  ...            0.440678    1.104626
24   0.813230             0.813953  ...            0.560000    1.255646
25   0.844358             0.868217  ...            0.567568    1.248553
26   0.813230             0.775194  ...            0.540541    1.300593
27   0.852140             0.875969  ...            0.476190    1.214057
28   0.887160             0.891473  ...            0.483871    1.270039
29   0.785992             0.767442  ...            0.575000    1.622990
30   0.875486             0.875969  ...            0.346154    1.239006
31   0.801556             0.767442  ...            0.582278    1.501563
32   0.859922             0.922481  ...            0.274510    1.248579
33   0.797665             0.790698  ...            0.222222    1.277458
34   0.817121             0.806202  ...            0.500000    1.214209
35   0.844358             0.868217  ...            0.507463    1.398120
36   0.832685             0.875969  ...            0.392857    1.252040
37   0.809339             0.775194  ...            0.433333    1.186464
38   0.824903             0.860465  ...            0.476190    1.359431
39   0.848249             0.813953  ...            0.542857    1.454843
40   0.805447             0.844961  ...            0.560000    1.418248
41   0.840467             0.821705  ...            0.451613    1.286110
42   0.848249             0.844961  ...            0.483871    1.341016
43   0.898833             0.883721  ...            0.476190    1.377485
44   0.875486             0.906977  ...            0.461538    1.435371
45   0.859922             0.844961  ...            0.477612    1.347861
46   0.891051             0.899225  ...            0.413793    1.471675
47   0.832685             0.829457  ...            0.575342    1.721794
48   0.859922             0.844961  ...            0.451613    1.427364
49   0.914397             0.945736  ...            0.500000    1.542637

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.779661            0.862069                  0.7      0.793651
TestLoader Losses 0.5052993560241441
@@@@ individuo =  9 [list([3]) list([5]) list([0, 7]) list([0, 0.09768904831161847])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])] 
 fitness =  0.7796610169491526
verifyEntry ([5], [4], [1, 7], [1, 0.12676812206472354])

achei cache 0.7796610169491526  individuo =  0 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])] 
 fitness =  0.7796610169491526
verifyEntry ([4], [2], [1, 3], [1, 5])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=8, bias=True)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=32, bias=True)
  (3): ReLU()
  (4): Linear(in_features=32, out_features=2, bias=True)
)

Best epoch: 3 with loss: 0.69 and acc: 50.00%
3229.95 total seconds elapsed. 161.50 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.501946             1.000000  ...            0.666667    0.709869
1    0.501946             1.000000  ...            0.666667    0.702526
2    0.501946             1.000000  ...            0.666667    0.691243
3    0.540856             0.937984  ...            0.682353    0.689743
4    0.622568             0.868217  ...            0.666667    0.692233
5    0.610895             0.984496  ...            0.611111    0.692973
6    0.712062             0.697674  ...            0.602740    0.695531
7    0.684825             0.736434  ...            0.632911    0.698540
8    0.645914             0.930233  ...            0.591549    0.698247
9    0.700389             0.666667  ...            0.611111    0.702802
10   0.692607             0.689922  ...            0.591549    0.705127
11   0.723735             0.860465  ...            0.550725    0.705134
12   0.669261             0.534884  ...            0.583333    0.707488
13   0.715953             0.891473  ...            0.550725    0.709505
14   0.743191             0.674419  ...            0.366667    0.713233
15   0.778210             0.891473  ...            0.594595    0.718090
16   0.700389             0.589147  ...            0.550725    0.720934
17   0.782101             0.736434  ...            0.542857    0.724245
18   0.758755             0.868217  ...            0.507463    0.727487
19   0.715953             0.581395  ...            0.583333    0.731341

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.779661            0.862069                  0.7      0.793651
TestLoader Losses 0.5994282294127901
@@@@ individuo =  8 [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
 list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
 list([1, 0.32935920000024327]) list([0, 3])
 list([0, 0.08762177840934646]) list([1, 5]) list([0, 0.1707647372757929])] 
 fitness =  0.7796610169491526
verifyEntry ([3], [5], [1, 7], [1, 0.12676812206472354])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.12676812206472354, inplace=False)
  (3): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.73 and acc: 46.67%
5811.71 total seconds elapsed. 116.23 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.536965             0.620155  ...            0.521739    0.727564
1    0.579767             0.527132  ...            0.062500    0.776678
2    0.630350             0.604651  ...            0.635294    0.815597
3    0.622568             0.682171  ...            0.344828    0.778898
4    0.723735             0.767442  ...            0.212766    0.830819
5    0.688716             0.651163  ...            0.514286    0.833353
6    0.715953             0.674419  ...            0.575342    0.890229
7    0.727626             0.775194  ...            0.421053    0.843507
8    0.778210             0.751938  ...            0.529412    0.889862
9    0.723735             0.751938  ...            0.421053    0.882700
10   0.801556             0.767442  ...            0.563380    0.984487
11   0.809339             0.821705  ...            0.346154    0.936369
12   0.774319             0.790698  ...            0.392857    0.965204
13   0.747082             0.759690  ...            0.500000    1.038549
14   0.782101             0.759690  ...            0.255319    0.987254
15   0.813230             0.829457  ...            0.529412    1.052404
16   0.848249             0.829457  ...            0.521739    1.126707
17   0.828794             0.829457  ...            0.552632    1.238134
18   0.805447             0.813953  ...            0.456140    1.036335
19   0.750973             0.751938  ...            0.602410    1.290989
20   0.754864             0.767442  ...            0.483871    0.999579
21   0.789883             0.759690  ...            0.602410    1.371739
22   0.793774             0.852713  ...            0.326531    1.108752
23   0.782101             0.759690  ...            0.440678    1.104626
24   0.813230             0.813953  ...            0.560000    1.255646
25   0.844358             0.868217  ...            0.567568    1.248553
26   0.813230             0.775194  ...            0.540541    1.300593
27   0.852140             0.875969  ...            0.476190    1.214057
28   0.887160             0.891473  ...            0.483871    1.270039
29   0.785992             0.767442  ...            0.575000    1.622990
30   0.875486             0.875969  ...            0.346154    1.239006
31   0.801556             0.767442  ...            0.582278    1.501563
32   0.859922             0.922481  ...            0.274510    1.248579
33   0.797665             0.790698  ...            0.222222    1.277458
34   0.817121             0.806202  ...            0.500000    1.214209
35   0.844358             0.868217  ...            0.507463    1.398120
36   0.832685             0.875969  ...            0.392857    1.252040
37   0.809339             0.775194  ...            0.433333    1.186464
38   0.824903             0.860465  ...            0.476190    1.359431
39   0.848249             0.813953  ...            0.542857    1.454843
40   0.805447             0.844961  ...            0.560000    1.418248
41   0.840467             0.821705  ...            0.451613    1.286110
42   0.848249             0.844961  ...            0.483871    1.341016
43   0.898833             0.883721  ...            0.476190    1.377485
44   0.875486             0.906977  ...            0.461538    1.435371
45   0.859922             0.844961  ...            0.477612    1.347861
46   0.891051             0.899225  ...            0.413793    1.471675
47   0.832685             0.829457  ...            0.575342    1.721794
48   0.859922             0.844961  ...            0.451613    1.427364
49   0.914397             0.945736  ...            0.500000    1.542637

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.779661            0.862069                  0.7      0.793651
TestLoader Losses 0.5052993560241441
@@@@ individuo =  2 [list([3]) list([5]) list([0, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])] 
 fitness =  0.7796610169491526
result (0, 0.7796610169491526)
result (1, 0.7966101694915254)
result (2, 0.7796610169491526)
result (3, 0.8135593220338984)
result (4, 0.8305084745762712)
result (5, 0.7796610169491526)
result (6, 0.6440677966101694)
result (7, 0.8305084745762712)
result (8, 0.7796610169491526)
result (9, 0.7796610169491526)


 Saving new generated items of geração  0

individuo [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])]  key  ([5], [4], [1, 7], [1, 0.12676812206472354]) 


individuo [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
 list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 3], [1, 12]) 


individuo [list([3]) list([5]) list([0, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])]  key  ([3], [5], [1, 7], [1, 0.12676812206472354]) 


individuo [list([4]) list([3]) list([0, 6]) list([0, 0.11110809481675672])
 list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
 list([1, 0.2574753409377971]) list([1, 4]) list([0, 0.25027141396285474])
 list([1, 4]) list([0, 0.3278614521834228])]  key  ([4], [3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4]) 


individuo [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([1, 8]) list([0, 0.556542328173652])
 list([1, 10]) list([0, 0.22107506160612872])]  key  ([5], [4], [1, 8], [1, 10]) 


individuo [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])]  key  ([5], [4], [1, 7], [1, 0.12676812206472354]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.4725973393754025])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([1, 0.2574753409377971]) list([1, 4]) list([0, 0.25027141396285474])
 list([1, 4]) list([0, 0.3278614521834228])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.2574753409377971], [1, 4], [1, 4]) 


individuo [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([1, 8]) list([0, 0.556542328173652])
 list([1, 10]) list([0, 0.22107506160612872])]  key  ([5], [4], [1, 8], [1, 10]) 


individuo [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
 list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
 list([1, 0.32935920000024327]) list([0, 3])
 list([0, 0.08762177840934646]) list([1, 5]) list([0, 0.1707647372757929])]  key  ([4], [2], [1, 3], [1, 5]) 


individuo [list([3]) list([5]) list([0, 7]) list([0, 0.09768904831161847])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])]  key  ([3], [5], [1, 7], [1, 0.12676812206472354]) 



@@@@ Reinsercao

cacheStore =  {'([4], [3], [1, 5], [1, 0.1262070664185572], [1, 5])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.847457627118644, '([5], [4], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [2], [1, 3], [1, 4], [1, 4])': 0.7288135593220338, '([2], [1], [1, 9], [1, 0.17065736910750998], [1, 11], [1, 0.3197351493711345], [1, 11], [1, 0.5177330618879615], [1, 9], [1, 3], [1, 0.27610931992185345])': 0.5084745762711864, '([3], [5], [1, 8], [1, 10])': 0.7457627118644068, '([2], [6], [1, 8])': 0.7796610169491526, '([1], [4], [1, 5], [1, 12])': 0.5084745762711864, '([1], [4], [1, 4], [1, 0.5131789330011404])': 0.4915254237288136, '([1], [6], [1, 5], [1, 7], [1, 0.06254698615663809])': 0.5084745762711864, '([4], [2], [1, 3], [1, 12])': 0.7966101694915254, '([3], [5], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4])': 0.8135593220338984, '([5], [4], [1, 8], [1, 10])': 0.8305084745762712, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.2574753409377971], [1, 4], [1, 4])': 0.6440677966101694, '([4], [2], [1, 3], [1, 5])': 0.7796610169491526}


 $$$$$$$$ Geração  1
population =  [[list([4]) list([2]) list([1, 5]) list([0, 0.4725973393754025])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([1, 8]) list([0, 0.556542328173652])
  list([1, 10]) list([0, 0.22107506160612872])]
 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
  list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([1, 8])
  list([0, 0.556542328173652]) list([1, 10])
  list([0, 0.22107506160612872])]
 [list([4]) list([3]) list([0, 6]) list([0, 0.11110809481675672])
  list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
  list([1, 0.2574753409377971]) list([1, 4])
  list([0, 0.25027141396285474]) list([1, 4])
  list([0, 0.3278614521834228])]
 [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
  list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
  list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.12676812206472354])]
 [list([3]) list([5]) list([0, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.12676812206472354])]
 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
  list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.12676812206472354])]
 [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
  list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
  list([1, 0.32935920000024327]) list([0, 3])
  list([0, 0.08762177840934646]) list([1, 5])
  list([0, 0.1707647372757929])]
 [list([3]) list([5]) list([0, 7]) list([0, 0.09768904831161847])
  list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.12676812206472354])]]
populationFitness =  [0.84745763 0.83050847 0.83050847 0.81355932 0.79661017 0.77966102
 0.77966102 0.77966102 0.77966102 0.77966102]
bestParent, bestParentFitness [list([4]) list([2]) list([1, 5]) list([0, 0.4725973393754025])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 0.847457627118644


@@@@ Selecao
indexParent 3
indexParent 4
indexParent 6
indexParent 0
indexParent 6
indexParent 3
indexParent 1
indexParent 7
indexParent 0
indexParent 5


@@@@ Crossover
crossoverPoint 4
crossoverPoint 10
crossoverPoint 2
not changing individuals
crossoverPoint 2


@@@@ Mutacao
Individuos para mutacao [6, 5]
@@@ mutated [0, 0.16625800380687808]
@@@ mutated [1, 0.3278614521834228]


@@@@ Calculando fitness
verifyEntry ([4], [2], [1, 3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=8, bias=True)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=32, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1262070664185572, inplace=False)
  (5): Linear(in_features=32, out_features=16, bias=True)
  (6): ReLU()
  (7): Linear(in_features=16, out_features=16, bias=True)
  (8): ReLU()
  (9): Dropout(p=0.3278614521834228, inplace=False)
  (10): Linear(in_features=16, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.69 and acc: 40.00%
3097.75 total seconds elapsed. 154.89 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.571984             0.627907  ...            0.651685    0.693444
1    0.521401             0.565891  ...            0.000000    0.694230
2    0.428016             0.333333  ...            0.157895    0.694222
3    0.466926             0.441860  ...            0.260870    0.694625
4    0.494163             0.511628  ...            0.406250    0.695157
5    0.525292             0.434109  ...            0.264151    0.695519
6    0.556420             0.511628  ...            0.269231    0.695641
7    0.556420             0.550388  ...            0.222222    0.695952
8    0.583658             0.457364  ...            0.190476    0.696424
9    0.587549             0.488372  ...            0.181818    0.697221
10   0.603113             0.403101  ...            0.190476    0.697047
11   0.579767             0.434109  ...            0.333333    0.698157
12   0.618677             0.356589  ...            0.266667    0.698944
13   0.591440             0.418605  ...            0.260870    0.699747
14   0.622568             0.387597  ...            0.297872    0.700917
15   0.626459             0.457364  ...            0.255319    0.703100
16   0.618677             0.364341  ...            0.338983    0.704182
17   0.692607             0.635659  ...            0.412698    0.705464
18   0.645914             0.457364  ...            0.352941    0.710694
19   0.661479             0.441860  ...            0.333333    0.711655

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.661017            0.448276             0.866667      0.565217
TestLoader Losses 0.6428606934466604
@@@@ individuo =  5 [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
 list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
 list([1, 0.2574753409377971]) list([1, 4]) list([0, 0.25027141396285474])
 list([1, 4]) list([1, 0.3278614521834228])] 
 fitness =  0.6610169491525424
verifyEntry ([4], [2], [1, 7], [1, 0.12676812206472354])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.12676812206472354, inplace=False)
  (3): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.72 and acc: 45.00%
3107.58 total seconds elapsed. 155.38 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.560311             0.596899  ...            0.000000    0.736589
1    0.552529             0.519380  ...            0.666667    0.718643
2    0.645914             0.534884  ...            0.444444    0.723517
3    0.653696             0.682171  ...            0.575342    0.749665
4    0.723735             0.798450  ...            0.492754    0.758536
5    0.712062             0.689922  ...            0.357143    0.767199
6    0.708171             0.651163  ...            0.393443    0.776050
7    0.727626             0.790698  ...            0.339623    0.791406
8    0.750973             0.720930  ...            0.419355    0.797280
9    0.715953             0.666667  ...            0.605263    0.849199
10   0.750973             0.720930  ...            0.605263    0.871013
11   0.785992             0.806202  ...            0.507463    0.830155
12   0.789883             0.829457  ...            0.313725    0.857593
13   0.770428             0.775194  ...            0.484848    0.864191
14   0.770428             0.798450  ...            0.406780    0.861090
15   0.747082             0.682171  ...            0.615385    0.985214
16   0.793774             0.806202  ...            0.535211    0.916368
17   0.778210             0.782946  ...            0.484848    0.892294
18   0.778210             0.813953  ...            0.555556    0.961718
19   0.762646             0.767442  ...            0.521739    0.932631

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.813559            0.896552             0.733333      0.825397
TestLoader Losses 0.48054381952447406
@@@@ individuo =  4 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])] 
 fitness =  0.8135593220338984
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.12676812206472354])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=4096, bias=True)
  (8): ReLU()
  (9): Linear(in_features=4096, out_features=128, bias=True)
  (10): ReLU()
  (11): Dropout(p=0.12676812206472354, inplace=False)
  (12): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 43.33%
3175.74 total seconds elapsed. 158.79 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.533074             0.837209  ...            0.666667    0.693799
1    0.517510             0.759690  ...            0.666667    0.693728
2    0.552529             0.573643  ...            0.643678    0.744744
3    0.700389             0.775194  ...            0.537313    0.982497
4    0.712062             0.674419  ...            0.579710    0.936125
5    0.719844             0.674419  ...            0.363636    0.852879
6    0.735409             0.782946  ...            0.406780    0.920913
7    0.750973             0.689922  ...            0.406780    0.969549
8    0.793774             0.744186  ...            0.357143    1.130133
9    0.762646             0.790698  ...            0.326531    0.979911
10   0.735409             0.682171  ...            0.555556    0.996682
11   0.778210             0.837209  ...            0.468750    1.082154
12   0.832685             0.798450  ...            0.575342    1.295713
13   0.809339             0.821705  ...            0.507463    1.153713
14   0.743191             0.728682  ...            0.586667    0.892707
15   0.727626             0.837209  ...            0.542857    0.934857
16   0.859922             0.883721  ...            0.560000    1.312738
17   0.856031             0.891473  ...            0.468750    1.284228
18   0.852140             0.883721  ...            0.461538    1.321319
19   0.805447             0.829457  ...            0.500000    0.976078

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.864407            0.965517             0.766667         0.875
TestLoader Losses 0.39633731266199534
@@@@ individuo =  6 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([1, 7])
 list([1, 0.12676812206472354])] 
 fitness =  0.864406779661017
verifyEntry ([4], [3], [1, 7], [1, 0.12676812206472354])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.12676812206472354, inplace=False)
  (3): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.72 and acc: 45.00%
4218.60 total seconds elapsed. 140.62 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.560311             0.596899  ...            0.000000    0.736589
1    0.552529             0.519380  ...            0.666667    0.718643
2    0.645914             0.534884  ...            0.444444    0.723517
3    0.653696             0.682171  ...            0.575342    0.749665
4    0.723735             0.798450  ...            0.492754    0.758536
5    0.712062             0.689922  ...            0.357143    0.767199
6    0.708171             0.651163  ...            0.393443    0.776050
7    0.727626             0.790698  ...            0.339623    0.791406
8    0.750973             0.720930  ...            0.419355    0.797280
9    0.715953             0.666667  ...            0.605263    0.849199
10   0.750973             0.720930  ...            0.605263    0.871013
11   0.785992             0.806202  ...            0.507463    0.830155
12   0.789883             0.829457  ...            0.313725    0.857593
13   0.770428             0.775194  ...            0.484848    0.864191
14   0.770428             0.798450  ...            0.406780    0.861090
15   0.747082             0.682171  ...            0.615385    0.985214
16   0.793774             0.806202  ...            0.535211    0.916368
17   0.778210             0.782946  ...            0.484848    0.892294
18   0.778210             0.813953  ...            0.555556    0.961718
19   0.762646             0.767442  ...            0.521739    0.932631
20   0.774319             0.775194  ...            0.597403    1.010675
21   0.817121             0.806202  ...            0.555556    0.970763
22   0.797665             0.875969  ...            0.492308    0.943417
23   0.797665             0.821705  ...            0.492308    0.926234
24   0.817121             0.751938  ...            0.521739    0.994405
25   0.809339             0.844961  ...            0.521739    1.002136
26   0.832685             0.852713  ...            0.521739    1.013136
27   0.817121             0.837209  ...            0.476190    0.969524
28   0.824903             0.798450  ...            0.578947    1.082360
29   0.817121             0.813953  ...            0.507463    1.023903

[30 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0   0.79661            0.862069             0.733333      0.806452
TestLoader Losses 0.48629831863661943
@@@@ individuo =  7 [list([4]) list([3]) list([0, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])] 
 fitness =  0.7966101694915254
verifyEntry ([5], [4], [1, 8], [1, 10])

achei cache 0.8305084745762712  individuo =  3 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([1, 8]) list([0, 0.556542328173652])
 list([1, 10]) list([0, 0.22107506160612872])] 
 fitness =  0.8305084745762712
verifyEntry ([5], [4], [1, 7], [1, 0.12676812206472354])

achei cache 0.7796610169491526  individuo =  8 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])] 
 fitness =  0.7796610169491526
verifyEntry ([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=4096, bias=True)
  (8): ReLU()
  (9): Linear(in_features=4096, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 40.00%
5065.41 total seconds elapsed. 126.64 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.501946             1.000000  ...            0.666667    0.692966
1    0.501946             0.992248  ...            0.659091    0.692481
2    0.591440             0.565891  ...            0.643678    0.693433
3    0.626459             0.813953  ...            0.421053    0.694669
4    0.642023             0.558140  ...            0.483871    0.695553
5    0.642023             0.844961  ...            0.589744    0.696855
6    0.661479             0.790698  ...            0.507937    0.698741
7    0.661479             0.697674  ...            0.413793    0.699631
8    0.673152             0.720930  ...            0.535211    0.708202
9    0.700389             0.627907  ...            0.400000    0.712206
10   0.645914             0.689922  ...            0.413793    0.722344
11   0.735409             0.713178  ...            0.529412    0.743512
12   0.723735             0.751938  ...            0.492308    0.760334
13   0.715953             0.782946  ...            0.433333    0.789513
14   0.704280             0.651163  ...            0.406780    0.802128
15   0.743191             0.775194  ...            0.413793    0.843535
16   0.747082             0.767442  ...            0.433333    0.882512
17   0.739300             0.705426  ...            0.433333    0.912205
18   0.758755             0.798450  ...            0.454545    0.962454
19   0.778210             0.759690  ...            0.514286    1.004752
20   0.789883             0.844961  ...            0.363636    1.002347
21   0.758755             0.759690  ...            0.419355    1.038510
22   0.797665             0.829457  ...            0.379310    1.077974
23   0.766537             0.775194  ...            0.419355    1.095006
24   0.770428             0.782946  ...            0.451613    1.099670
25   0.809339             0.821705  ...            0.400000    1.123504
26   0.774319             0.775194  ...            0.451613    1.133100
27   0.805447             0.767442  ...            0.426230    1.131795
28   0.782101             0.751938  ...            0.419355    1.153270
29   0.754864             0.798450  ...            0.426230    1.141760
30   0.824903             0.844961  ...            0.454545    1.180198
31   0.856031             0.852713  ...            0.400000    1.193376
32   0.809339             0.806202  ...            0.454545    1.217785
33   0.801556             0.813953  ...            0.447761    1.246041
34   0.797665             0.821705  ...            0.400000    1.204242
35   0.840467             0.829457  ...            0.424242    1.253031
36   0.836576             0.899225  ...            0.400000    1.230450
37   0.813230             0.790698  ...            0.447761    1.282051
38   0.813230             0.837209  ...            0.400000    1.235096
39   0.852140             0.875969  ...            0.419355    1.237735

[40 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.813559            0.793103             0.833333      0.807018
TestLoader Losses 0.46044524948475724
@@@@ individuo =  9 [list([5]) list([4]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.8135593220338984
verifyEntry ([4], [3], [1, 12])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=4096, bias=True)
  (1): ReLU()
  (2): Linear(in_features=4096, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.74 and acc: 46.67%
4251.42 total seconds elapsed. 141.71 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.556420             0.558140  ...            0.437500    0.742659
1    0.642023             0.643411  ...            0.260870    0.778165
2    0.700389             0.651163  ...            0.632911    0.895854
3    0.661479             0.658915  ...            0.269231    0.843550
4    0.700389             0.720930  ...            0.625000    0.985794
5    0.758755             0.697674  ...            0.575342    0.916579
6    0.750973             0.759690  ...            0.594595    0.986016
7    0.762646             0.767442  ...            0.426230    0.923037
8    0.778210             0.759690  ...            0.542857    1.016070
9    0.778210             0.751938  ...            0.468750    0.967550
10   0.723735             0.751938  ...            0.500000    0.983250
11   0.793774             0.829457  ...            0.597403    1.076776
12   0.867704             0.875969  ...            0.468750    1.028757
13   0.789883             0.775194  ...            0.560000    1.184661
14   0.754864             0.751938  ...            0.468750    1.042354
15   0.883268             0.899225  ...            0.440678    1.112606
16   0.813230             0.767442  ...            0.484848    1.144460
17   0.871595             0.891473  ...            0.567568    1.279804
18   0.809339             0.829457  ...            0.476190    1.100514
19   0.879377             0.875969  ...            0.339623    1.195087
20   0.813230             0.782946  ...            0.560000    1.248480
21   0.844358             0.837209  ...            0.552632    1.417637
22   0.836576             0.891473  ...            0.440678    1.148703
23   0.844358             0.806202  ...            0.468750    1.199854
24   0.867704             0.899225  ...            0.440678    1.232750
25   0.801556             0.759690  ...            0.407407    1.086725
26   0.875486             0.875969  ...            0.555556    1.286303
27   0.902724             0.930233  ...            0.507937    1.235305
28   0.894942             0.868217  ...            0.507042    1.336438
29   0.898833             0.906977  ...            0.448276    1.209164

[30 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.762712            0.586207             0.933333      0.708333
TestLoader Losses 0.47816063893043387
@@@@ individuo =  0 [list([4]) list([3]) list([0, 6]) list([0, 0.11110809481675672])
 list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7627118644067796
verifyEntry ([3], [5])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.77 and acc: 43.33%
5646.46 total seconds elapsed. 112.93 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.498054             0.496124  ...            0.666667    1.025037
1    0.575875             0.565891  ...            0.327273    0.766793
2    0.677043             0.713178  ...            0.575342    0.829502
3    0.684825             0.697674  ...            0.366667    0.887368
4    0.743191             0.720930  ...            0.500000    0.911091
5    0.789883             0.782946  ...            0.419355    0.913505
6    0.731518             0.798450  ...            0.244898    0.989474
7    0.715953             0.697674  ...            0.605263    1.094740
8    0.801556             0.790698  ...            0.563380    1.030886
9    0.778210             0.829457  ...            0.114286    1.198488
10   0.645914             0.635659  ...            0.521739    1.082553
11   0.848249             0.813953  ...            0.529412    1.058966
12   0.785992             0.798450  ...            0.426230    1.022884
13   0.813230             0.806202  ...            0.575342    1.185688
14   0.789883             0.844961  ...            0.563380    1.147642
15   0.735409             0.682171  ...            0.492308    1.087843
16   0.836576             0.875969  ...            0.451613    1.074504
17   0.785992             0.798450  ...            0.563380    1.165585
18   0.887160             0.914729  ...            0.542857    1.199733
19   0.898833             0.891473  ...            0.521739    1.195906
20   0.824903             0.829457  ...            0.500000    1.112754
21   0.852140             0.891473  ...            0.244898    1.221480
22   0.809339             0.775194  ...            0.483871    1.153486
23   0.828794             0.829457  ...            0.540541    1.311195
24   0.801556             0.821705  ...            0.555556    1.287609
25   0.801556             0.775194  ...            0.542857    1.308811
26   0.832685             0.868217  ...            0.529412    1.250210
27   0.875486             0.875969  ...            0.433333    1.189197
28   0.844358             0.844961  ...            0.537313    1.280552
29   0.813230             0.844961  ...            0.433333    1.217589
30   0.836576             0.775194  ...            0.500000    1.242629
31   0.867704             0.914729  ...            0.406780    1.218672
32   0.859922             0.829457  ...            0.523077    1.239060
33   0.856031             0.875969  ...            0.392857    1.200778
34   0.898833             0.906977  ...            0.406780    1.216304
35   0.852140             0.821705  ...            0.459016    1.186261
36   0.813230             0.844961  ...            0.451613    1.204515
37   0.867704             0.852713  ...            0.370370    1.286097
38   0.817121             0.798450  ...            0.515152    1.323160
39   0.910506             0.914729  ...            0.476190    1.274025
40   0.867704             0.852713  ...            0.542857    1.364990
41   0.875486             0.899225  ...            0.527778    1.437752
42   0.879377             0.875969  ...            0.483871    1.263053
43   0.891051             0.899225  ...            0.459016    1.257284
44   0.894942             0.868217  ...            0.550725    1.343194
45   0.856031             0.875969  ...            0.333333    1.326338
46   0.844358             0.844961  ...            0.483871    1.267255
47   0.863813             0.837209  ...            0.363636    1.330328
48   0.883268             0.899225  ...            0.285714    1.375628
49   0.848249             0.852713  ...            0.468750    1.348579

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.830508            0.827586             0.833333      0.827586
TestLoader Losses 0.46857242058899445
@@@@ individuo =  1 [list([3]) list([5]) list([0, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.8305084745762712
verifyEntry ([3], [5], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.1262070664185572, inplace=False)
  (3): Linear(in_features=32, out_features=16, bias=True)
  (4): ReLU()
  (5): Linear(in_features=16, out_features=16, bias=True)
  (6): ReLU()
  (7): Dropout(p=0.3278614521834228, inplace=False)
  (8): Linear(in_features=16, out_features=2, bias=True)
)

Best epoch: 2 with loss: 0.69 and acc: 46.67%
5649.29 total seconds elapsed. 112.99 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.494163             0.759690  ...            0.666667    0.696990
1    0.533074             0.798450  ...            0.651163    0.695122
2    0.544747             0.550388  ...            0.666667    0.693810
3    0.614786             0.472868  ...            0.650602    0.695579
4    0.614786             0.666667  ...            0.055556    0.697022
5    0.642023             0.511628  ...            0.108108    0.716294
6    0.696498             0.682171  ...            0.058824    0.747530
7    0.610895             0.658915  ...            0.255319    0.740437
8    0.669261             0.728682  ...            0.370370    0.762418
9    0.692607             0.627907  ...            0.634146    0.817772
10   0.715953             0.689922  ...            0.626506    0.795557
11   0.708171             0.790698  ...            0.451613    0.862399
12   0.735409             0.767442  ...            0.500000    0.845155
13   0.782101             0.806202  ...            0.484848    0.947865
14   0.754864             0.775194  ...            0.477612    0.870634
15   0.766537             0.751938  ...            0.542857    0.894956
16   0.770428             0.837209  ...            0.483871    0.941434
17   0.750973             0.720930  ...            0.535211    0.955704
18   0.809339             0.852713  ...            0.589744    1.024177
19   0.793774             0.883721  ...            0.529412    0.912545
20   0.836576             0.844961  ...            0.492308    1.198912
21   0.766537             0.798450  ...            0.515152    0.919254
22   0.824903             0.837209  ...            0.594595    1.110650
23   0.801556             0.852713  ...            0.607595    0.986221
24   0.817121             0.883721  ...            0.537313    1.000463
25   0.801556             0.837209  ...            0.466667    1.082635
26   0.747082             0.775194  ...            0.456140    0.940792
27   0.848249             0.891473  ...            0.415094    1.260808
28   0.805447             0.813953  ...            0.440678    1.016328
29   0.817121             0.837209  ...            0.436364    1.176129
30   0.856031             0.844961  ...            0.413793    1.204739
31   0.793774             0.790698  ...            0.451613    0.899362
32   0.824903             0.860465  ...            0.521739    1.179279
33   0.801556             0.868217  ...            0.583333    0.988567
34   0.813230             0.821705  ...            0.484848    1.024769
35   0.844358             0.852713  ...            0.491803    1.138478
36   0.805447             0.813953  ...            0.440678    1.192404
37   0.836576             0.844961  ...            0.440678    1.164385
38   0.840467             0.837209  ...            0.507463    1.151718
39   0.863813             0.914729  ...            0.451613    1.463522
40   0.840467             0.844961  ...            0.459016    1.223088
41   0.832685             0.829457  ...            0.523077    0.987603
42   0.852140             0.922481  ...            0.492308    1.290107
43   0.840467             0.868217  ...            0.476190    1.302586
44   0.875486             0.860465  ...            0.477612    1.617910
45   0.867704             0.899225  ...            0.413793    1.061768
46   0.824903             0.806202  ...            0.456140    1.425162
47   0.824903             0.821705  ...            0.535211    1.347441
48   0.879377             0.906977  ...            0.575342    1.643240
49   0.821012             0.852713  ...            0.500000    0.962911

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.813559            0.827586                  0.8      0.813559
TestLoader Losses 0.4665363461284314
@@@@ individuo =  2 [list([3]) list([5]) list([0, 6]) list([0, 0.11110809481675672])
 list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
 list([1, 0.2574753409377971]) list([1, 4]) list([0, 0.25027141396285474])
 list([1, 4]) list([1, 0.3278614521834228])] 
 fitness =  0.8135593220338984
result (0, 0.7627118644067796)
result (1, 0.8305084745762712)
result (2, 0.8135593220338984)
result (3, 0.8305084745762712)
result (4, 0.8135593220338984)
result (5, 0.6610169491525424)
result (6, 0.864406779661017)
result (7, 0.7966101694915254)
result (8, 0.7796610169491526)
result (9, 0.8135593220338984)


 Saving new generated items of geração  1

individuo [list([4]) list([3]) list([0, 6]) list([0, 0.11110809481675672])
 list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [3], [1, 12]) 


individuo [list([3]) list([5]) list([0, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([3], [5]) 


individuo [list([3]) list([5]) list([0, 6]) list([0, 0.11110809481675672])
 list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
 list([1, 0.2574753409377971]) list([1, 4]) list([0, 0.25027141396285474])
 list([1, 4]) list([1, 0.3278614521834228])]  key  ([3], [5], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228]) 


individuo [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([1, 8]) list([0, 0.556542328173652])
 list([1, 10]) list([0, 0.22107506160612872])]  key  ([5], [4], [1, 8], [1, 10]) 


individuo [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])]  key  ([4], [2], [1, 7], [1, 0.12676812206472354]) 


individuo [list([4]) list([2]) list([1, 3]) list([0, 0.4097988439930561])
 list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
 list([1, 0.2574753409377971]) list([1, 4]) list([0, 0.25027141396285474])
 list([1, 4]) list([1, 0.3278614521834228])]  key  ([4], [2], [1, 3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([1, 7])
 list([1, 0.12676812206472354])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.12676812206472354]) 


individuo [list([4]) list([3]) list([0, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])]  key  ([4], [3], [1, 7], [1, 0.12676812206472354]) 


individuo [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.12676812206472354])]  key  ([5], [4], [1, 7], [1, 0.12676812206472354]) 


individuo [list([5]) list([4]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12]) 



@@@@ Reinsercao

cacheStore =  {'([4], [3], [1, 5], [1, 0.1262070664185572], [1, 5])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.847457627118644, '([5], [4], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [2], [1, 3], [1, 4], [1, 4])': 0.7288135593220338, '([2], [1], [1, 9], [1, 0.17065736910750998], [1, 11], [1, 0.3197351493711345], [1, 11], [1, 0.5177330618879615], [1, 9], [1, 3], [1, 0.27610931992185345])': 0.5084745762711864, '([3], [5], [1, 8], [1, 10])': 0.7457627118644068, '([2], [6], [1, 8])': 0.7796610169491526, '([1], [4], [1, 5], [1, 12])': 0.5084745762711864, '([1], [4], [1, 4], [1, 0.5131789330011404])': 0.4915254237288136, '([1], [6], [1, 5], [1, 7], [1, 0.06254698615663809])': 0.5084745762711864, '([4], [2], [1, 3], [1, 12])': 0.7966101694915254, '([3], [5], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4])': 0.8135593220338984, '([5], [4], [1, 8], [1, 10])': 0.8305084745762712, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.2574753409377971], [1, 4], [1, 4])': 0.6440677966101694, '([4], [2], [1, 3], [1, 5])': 0.7796610169491526, '([4], [3], [1, 12])': 0.7627118644067796, '([3], [5])': 0.8305084745762712, '([3], [5], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.8135593220338984, '([4], [2], [1, 7], [1, 0.12676812206472354])': 0.8135593220338984, '([4], [2], [1, 3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.6610169491525424, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.12676812206472354])': 0.864406779661017, '([4], [3], [1, 7], [1, 0.12676812206472354])': 0.7966101694915254, '([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.8135593220338984}


 $$$$$$$$ Geração  2
population =  [[list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([1, 7])
  list([1, 0.12676812206472354])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([3]) list([5]) list([0, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([0, 10])
  list([1, 0.15153638994891563]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([1, 8]) list([0, 0.556542328173652])
  list([1, 10]) list([0, 0.22107506160612872])]
 [list([3]) list([5]) list([0, 6]) list([0, 0.11110809481675672])
  list([1, 5]) list([1, 0.1262070664185572]) list([0, 10])
  list([1, 0.2574753409377971]) list([1, 4])
  list([0, 0.25027141396285474]) list([1, 4])
  list([1, 0.3278614521834228])]
 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
  list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.12676812206472354])]
 [list([5]) list([4]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([4]) list([3]) list([0, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.12676812206472354])]
 [list([5]) list([4]) list([0, 11]) list([1, 0.5950958103579727])
  list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.12676812206472354])]
 [list([4]) list([3]) list([0, 6]) list([0, 0.11110809481675672])
  list([0, 8]) list([1, 0.1870361167364643]) list([0, 8])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]]
populationFitness =  [0.86440678 0.84745763 0.83050847 0.83050847 0.81355932 0.81355932
 0.81355932 0.79661017 0.77966102 0.76271186]
bestParent, bestParentFitness [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([1, 7])
 list([1, 0.12676812206472354])] 0.864406779661017


@@@@ Selecao
indexParent 2
indexParent 0
indexParent 6
indexParent 1
indexParent 5
indexParent 2
indexParent 2
indexParent 2
indexParent 5
indexParent 5


@@@@ Crossover
crossoverPoint 2
crossoverPoint 5
crossoverPoint 3
crossoverPoint 4
crossoverPoint 3


@@@@ Mutacao
Individuos para mutacao [3, 0]
@@@ mutated [1, 7]
@@@ mutated [1, 0.42282557555718114]


@@@@ Calculando fitness
verifyEntry ([4], [2])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=2, bias=True)
)

Best epoch: 2 with loss: 0.70 and acc: 40.00%
3065.87 total seconds elapsed. 153.29 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.540856             0.449612  ...            0.542857    0.706955
1    0.556420             0.775194  ...            0.297872    0.708168
2    0.634241             0.488372  ...            0.444444    0.703315
3    0.661479             0.612403  ...            0.468750    0.721405
4    0.715953             0.813953  ...            0.406780    0.729047
5    0.704280             0.713178  ...            0.500000    0.734248
6    0.723735             0.689922  ...            0.594595    0.761927
7    0.735409             0.705426  ...            0.412698    0.748508
8    0.743191             0.720930  ...            0.583333    0.759855
9    0.762646             0.813953  ...            0.602740    0.778164
10   0.758755             0.751938  ...            0.583333    0.776441
11   0.762646             0.751938  ...            0.437500    0.778181
12   0.727626             0.744186  ...            0.521739    0.786284
13   0.731518             0.620155  ...            0.594595    0.809335
14   0.739300             0.806202  ...            0.412698    0.795483
15   0.750973             0.705426  ...            0.602740    0.819553
16   0.782101             0.821705  ...            0.542857    0.807983
17   0.743191             0.759690  ...            0.454545    0.806875
18   0.785992             0.798450  ...            0.500000    0.812670
19   0.754864             0.782946  ...            0.419355    0.816167

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.728814             0.62069             0.833333      0.692308
TestLoader Losses 0.5302637815475464
@@@@ individuo =  2 [list([4]) list([2]) list([0, 11]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7288135593220338
verifyEntry ([4], [2], [1, 7])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.71 and acc: 48.33%
3070.30 total seconds elapsed. 153.51 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.552529             0.581395  ...            0.000000    0.728086
1    0.591440             0.511628  ...            0.659091    0.709612
2    0.642023             0.736434  ...            0.492754    0.723814
3    0.712062             0.635659  ...            0.555556    0.755165
4    0.700389             0.759690  ...            0.430769    0.765959
5    0.688716             0.658915  ...            0.555556    0.785650
6    0.743191             0.759690  ...            0.555556    0.801271
7    0.715953             0.658915  ...            0.625000    0.869578
8    0.704280             0.728682  ...            0.575342    0.832605
9    0.785992             0.875969  ...            0.430769    0.824373
10   0.739300             0.697674  ...            0.521739    0.859289
11   0.758755             0.720930  ...            0.555556    0.877052
12   0.782101             0.829457  ...            0.507463    0.879345
13   0.723735             0.682171  ...            0.350877    0.863405
14   0.789883             0.790698  ...            0.555556    0.916147
15   0.805447             0.813953  ...            0.578947    0.987337
16   0.824903             0.806202  ...            0.578947    0.979779
17   0.723735             0.798450  ...            0.468750    0.913185
18   0.762646             0.736434  ...            0.477612    0.951667
19   0.785992             0.837209  ...            0.586667    0.996986

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.762712            0.931034                  0.6      0.794118
TestLoader Losses 0.5087997761823363
@@@@ individuo =  5 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7627118644067796
verifyEntry ([4], [2], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.42282557555718114, inplace=False)
  (3): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 2 with loss: 0.72 and acc: 41.67%
3071.25 total seconds elapsed. 153.56 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.552529             0.620155  ...            0.000000    0.742055
1    0.564202             0.519380  ...            0.666667    0.736357
2    0.610895             0.581395  ...            0.240000    0.715873
3    0.630350             0.666667  ...            0.514286    0.730253
4    0.657588             0.751938  ...            0.594595    0.740355
5    0.626459             0.651163  ...            0.385965    0.740434
6    0.634241             0.589147  ...            0.379310    0.747403
7    0.700389             0.790698  ...            0.274510    0.754313
8    0.704280             0.651163  ...            0.535211    0.759708
9    0.727626             0.713178  ...            0.594595    0.789427
10   0.747082             0.720930  ...            0.631579    0.814471
11   0.743191             0.736434  ...            0.514286    0.790188
12   0.731518             0.782946  ...            0.346154    0.799673
13   0.739300             0.713178  ...            0.555556    0.820815
14   0.731518             0.744186  ...            0.500000    0.824519
15   0.750973             0.689922  ...            0.617284    0.939997
16   0.774319             0.751938  ...            0.535211    0.853877
17   0.754864             0.775194  ...            0.440678    0.833195
18   0.750973             0.751938  ...            0.535211    0.879670
19   0.700389             0.713178  ...            0.477612    0.857262

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0   0.79661            0.793103                  0.8      0.793103
TestLoader Losses 0.5122153486235667
@@@@ individuo =  4 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7966101694915254
verifyEntry ([3], [5], [1, 7], [1, 0.5950958103579727], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.5950958103579727, inplace=False)
  (3): Linear(in_features=128, out_features=128, bias=True)
  (4): ReLU()
  (5): Dropout(p=0.42282557555718114, inplace=False)
  (6): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 46.67%
5739.01 total seconds elapsed. 114.78 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.498054             0.457364  ...            0.666667    0.702121
1    0.498054             0.596899  ...            0.611111    0.692877
2    0.536965             0.612403  ...            0.651685    0.694026
3    0.540856             0.496124  ...            0.659091    0.697373
4    0.505837             0.488372  ...            0.433333    0.698476
5    0.583658             0.658915  ...            0.301887    0.704901
6    0.575875             0.651163  ...            0.400000    0.713330
7    0.583658             0.728682  ...            0.430769    0.716110
8    0.630350             0.643411  ...            0.366667    0.731936
9    0.622568             0.705426  ...            0.635294    0.746284
10   0.610895             0.782946  ...            0.470588    0.739071
11   0.661479             0.806202  ...            0.447761    0.758558
12   0.634241             0.798450  ...            0.514286    0.754084
13   0.579767             0.891473  ...            0.586667    0.711285
14   0.618677             0.844961  ...            0.280000    0.804002
15   0.591440             0.852713  ...            0.057143    0.773120
16   0.610895             0.860465  ...            0.459016    0.734269
17   0.591440             0.922481  ...            0.451613    0.744454
18   0.626459             0.829457  ...            0.436364    0.788183
19   0.610895             0.782946  ...            0.514286    0.726523
20   0.642023             0.906977  ...            0.594595    0.726335
21   0.626459             0.860465  ...            0.535211    0.742860
22   0.657588             0.914729  ...            0.582278    0.781854
23   0.696498             0.899225  ...            0.575342    0.805070
24   0.715953             0.883721  ...            0.535211    0.786047
25   0.673152             0.891473  ...            0.613333    0.738863
26   0.645914             0.945736  ...            0.535211    0.749558
27   0.661479             0.891473  ...            0.555556    0.787987
28   0.665370             0.883721  ...            0.615385    0.827932
29   0.618677             0.914729  ...            0.666667    0.699301
30   0.560311             0.953488  ...            0.333333    0.766632
31   0.614786             0.922481  ...            0.575000    0.806931
32   0.645914             0.945736  ...            0.550725    0.761211
33   0.638132             0.899225  ...            0.535211    0.815180
34   0.704280             0.914729  ...            0.594595    0.792340
35   0.688716             0.930233  ...            0.555556    0.840882
36   0.708171             0.914729  ...            0.520548    0.854098
37   0.669261             0.930233  ...            0.626506    0.829767
38   0.645914             0.906977  ...            0.623377    0.730024
39   0.692607             0.891473  ...            0.540541    0.826311
40   0.669261             0.899225  ...            0.555556    0.780343
41   0.684825             0.899225  ...            0.500000    0.832695
42   0.677043             0.937984  ...            0.521739    0.887731
43   0.692607             0.906977  ...            0.477612    0.963952
44   0.638132             0.930233  ...            0.500000    0.837170
45   0.700389             0.891473  ...            0.529412    0.823699
46   0.649805             0.906977  ...            0.571429    0.731022
47   0.645914             0.914729  ...            0.605263    0.769159
48   0.622568             0.968992  ...            0.529412    0.767887
49   0.642023             0.899225  ...            0.555556    0.802507

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.779661            0.896552             0.666667           0.8
TestLoader Losses 0.536631311400462
@@@@ individuo =  7 [list([3]) list([5]) list([1, 7]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7796610169491526
verifyEntry ([3], [5], [1, 7])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.73 and acc: 46.67%
5740.83 total seconds elapsed. 114.82 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.571984             0.674419  ...            0.666667    0.725651
1    0.607004             0.496124  ...            0.666667    0.860622
2    0.599222             0.651163  ...            0.537313    0.738804
3    0.673152             0.581395  ...            0.649351    0.843784
4    0.669261             0.728682  ...            0.500000    0.820747
5    0.680934             0.658915  ...            0.632911    0.939986
6    0.715953             0.744186  ...            0.363636    0.847080
7    0.723735             0.666667  ...            0.604651    1.134820
8    0.747082             0.759690  ...            0.575342    0.939206
9    0.789883             0.798450  ...            0.466667    0.906141
10   0.727626             0.744186  ...            0.605263    1.083005
11   0.774319             0.720930  ...            0.477612    0.970120
12   0.762646             0.813953  ...            0.476190    0.980648
13   0.727626             0.643411  ...            0.466667    0.919920
14   0.785992             0.806202  ...            0.567568    1.072497
15   0.836576             0.852713  ...            0.477612    1.053068
16   0.859922             0.837209  ...            0.578947    1.200774
17   0.712062             0.720930  ...            0.200000    1.081031
18   0.723735             0.689922  ...            0.578947    1.116948
19   0.731518             0.775194  ...            0.535211    1.059120
20   0.824903             0.821705  ...            0.421053    1.027991
21   0.793774             0.782946  ...            0.527778    1.171866
22   0.844358             0.821705  ...            0.520548    1.214282
23   0.863813             0.868217  ...            0.492308    1.148730
24   0.848249             0.868217  ...            0.514286    1.206940
25   0.856031             0.860465  ...            0.413793    1.136603
26   0.828794             0.883721  ...            0.440678    1.165637
27   0.836576             0.806202  ...            0.491803    1.164287
28   0.863813             0.852713  ...            0.500000    1.197628
29   0.894942             0.914729  ...            0.413793    1.205861
30   0.782101             0.759690  ...            0.617284    1.633664
31   0.832685             0.837209  ...            0.466667    1.214960
32   0.844358             0.852713  ...            0.567901    1.597276
33   0.739300             0.736434  ...            0.157895    1.260511
34   0.867704             0.852713  ...            0.500000    1.257956
35   0.894942             0.937984  ...            0.514286    1.342103
36   0.867704             0.860465  ...            0.476190    1.282336
37   0.856031             0.860465  ...            0.500000    1.289378
38   0.910506             0.937984  ...            0.484848    1.371293
39   0.894942             0.899225  ...            0.459016    1.319805
40   0.871595             0.875969  ...            0.492754    1.434640
41   0.891051             0.891473  ...            0.476190    1.376819
42   0.863813             0.868217  ...            0.476190    1.351167
43   0.879377             0.875969  ...            0.507042    1.584581
44   0.859922             0.868217  ...            0.492308    1.428170
45   0.898833             0.891473  ...            0.507042    1.622501
46   0.852140             0.875969  ...            0.400000    1.365014
47   0.906615             0.883721  ...            0.507463    1.517293
48   0.875486             0.906977  ...            0.507937    1.465913
49   0.871595             0.852713  ...            0.483871    1.478356

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.830508            0.793103             0.866667      0.821429
TestLoader Losses 0.45927392325158845
@@@@ individuo =  3 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.8305084745762712
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])

achei cache 0.847457627118644  individuo =  6 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.847457627118644
verifyEntry ([4], [2], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.42282557555718114, inplace=False)
  (3): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 2 with loss: 0.72 and acc: 41.67%
3075.70 total seconds elapsed. 153.79 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.552529             0.620155  ...            0.000000    0.742055
1    0.564202             0.519380  ...            0.666667    0.736357
2    0.610895             0.581395  ...            0.240000    0.715873
3    0.630350             0.666667  ...            0.514286    0.730253
4    0.657588             0.751938  ...            0.594595    0.740355
5    0.626459             0.651163  ...            0.385965    0.740434
6    0.634241             0.589147  ...            0.379310    0.747403
7    0.700389             0.790698  ...            0.274510    0.754313
8    0.704280             0.651163  ...            0.535211    0.759708
9    0.727626             0.713178  ...            0.594595    0.789427
10   0.747082             0.720930  ...            0.631579    0.814471
11   0.743191             0.736434  ...            0.514286    0.790188
12   0.731518             0.782946  ...            0.346154    0.799673
13   0.739300             0.713178  ...            0.555556    0.820815
14   0.731518             0.744186  ...            0.500000    0.824519
15   0.750973             0.689922  ...            0.617284    0.939997
16   0.774319             0.751938  ...            0.535211    0.853877
17   0.754864             0.775194  ...            0.440678    0.833195
18   0.750973             0.751938  ...            0.535211    0.879670
19   0.700389             0.713178  ...            0.477612    0.857262

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0   0.79661            0.793103                  0.8      0.793103
TestLoader Losses 0.5122153486235667
@@@@ individuo =  9 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7966101694915254
verifyEntry ([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])

achei cache 0.8135593220338984  individuo =  1 [list([5]) list([4]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.8135593220338984
verifyEntry ([3], [5], [1, 7])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.73 and acc: 46.67%
5742.60 total seconds elapsed. 114.85 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.571984             0.674419  ...            0.666667    0.725651
1    0.607004             0.496124  ...            0.666667    0.860622
2    0.599222             0.651163  ...            0.537313    0.738804
3    0.673152             0.581395  ...            0.649351    0.843784
4    0.669261             0.728682  ...            0.500000    0.820747
5    0.680934             0.658915  ...            0.632911    0.939986
6    0.715953             0.744186  ...            0.363636    0.847080
7    0.723735             0.666667  ...            0.604651    1.134820
8    0.747082             0.759690  ...            0.575342    0.939206
9    0.789883             0.798450  ...            0.466667    0.906141
10   0.727626             0.744186  ...            0.605263    1.083005
11   0.774319             0.720930  ...            0.477612    0.970120
12   0.762646             0.813953  ...            0.476190    0.980648
13   0.727626             0.643411  ...            0.466667    0.919920
14   0.785992             0.806202  ...            0.567568    1.072497
15   0.836576             0.852713  ...            0.477612    1.053068
16   0.859922             0.837209  ...            0.578947    1.200774
17   0.712062             0.720930  ...            0.200000    1.081031
18   0.723735             0.689922  ...            0.578947    1.116948
19   0.731518             0.775194  ...            0.535211    1.059120
20   0.824903             0.821705  ...            0.421053    1.027991
21   0.793774             0.782946  ...            0.527778    1.171866
22   0.844358             0.821705  ...            0.520548    1.214282
23   0.863813             0.868217  ...            0.492308    1.148730
24   0.848249             0.868217  ...            0.514286    1.206940
25   0.856031             0.860465  ...            0.413793    1.136603
26   0.828794             0.883721  ...            0.440678    1.165637
27   0.836576             0.806202  ...            0.491803    1.164287
28   0.863813             0.852713  ...            0.500000    1.197628
29   0.894942             0.914729  ...            0.413793    1.205861
30   0.782101             0.759690  ...            0.617284    1.633664
31   0.832685             0.837209  ...            0.466667    1.214960
32   0.844358             0.852713  ...            0.567901    1.597276
33   0.739300             0.736434  ...            0.157895    1.260511
34   0.867704             0.852713  ...            0.500000    1.257956
35   0.894942             0.937984  ...            0.514286    1.342103
36   0.867704             0.860465  ...            0.476190    1.282336
37   0.856031             0.860465  ...            0.500000    1.289378
38   0.910506             0.937984  ...            0.484848    1.371293
39   0.894942             0.899225  ...            0.459016    1.319805
40   0.871595             0.875969  ...            0.492754    1.434640
41   0.891051             0.891473  ...            0.476190    1.376819
42   0.863813             0.868217  ...            0.476190    1.351167
43   0.879377             0.875969  ...            0.507042    1.584581
44   0.859922             0.868217  ...            0.492308    1.428170
45   0.898833             0.891473  ...            0.507042    1.622501
46   0.852140             0.875969  ...            0.400000    1.365014
47   0.906615             0.883721  ...            0.507463    1.517293
48   0.875486             0.906977  ...            0.507937    1.465913
49   0.871595             0.852713  ...            0.483871    1.478356

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.830508            0.793103             0.866667      0.821429
TestLoader Losses 0.45927392325158845
@@@@ individuo =  8 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.8305084745762712
verifyEntry ([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=4096, bias=True)
  (8): ReLU()
  (9): Linear(in_features=4096, out_features=128, bias=True)
  (10): ReLU()
  (11): Dropout(p=0.42282557555718114, inplace=False)
  (12): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 5 with loss: 0.69 and acc: 50.00%
5894.75 total seconds elapsed. 117.90 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.517510             0.310078  ...            0.666667    0.693444
1    0.482490             0.589147  ...            0.666667    0.693149
2    0.513619             0.527132  ...            0.666667    0.693160
3    0.517510             0.534884  ...            0.000000    0.693152
4    0.521401             0.325581  ...            0.666667    0.693148
5    0.501946             0.364341  ...            0.000000    0.693147
6    0.420233             0.472868  ...            0.666667    0.693150
7    0.529183             0.806202  ...            0.000000    0.693155
8    0.498054             0.341085  ...            0.000000    0.693285
9    0.509728             0.418605  ...            0.666667    0.693147
10   0.463035             0.302326  ...            0.000000    0.693170
11   0.517510             0.503876  ...            0.666667    0.693151
12   0.505837             0.279070  ...            0.000000    0.693234
13   0.517510             0.155039  ...            0.000000    0.693192
14   0.513619             0.434109  ...            0.000000    0.693160
15   0.494163             0.379845  ...            0.000000    0.693164
16   0.525292             0.217054  ...            0.000000    0.693363
17   0.517510             0.434109  ...            0.666667    0.693150
18   0.505837             0.395349  ...            0.000000    0.693193
19   0.490272             0.767442  ...            0.666667    0.693349
20   0.466926             0.806202  ...            0.666667    0.693206
21   0.478599             0.744186  ...            0.666667    0.693150
22   0.482490             0.674419  ...            0.666667    0.693159
23   0.498054             0.658915  ...            0.666667    0.693155
24   0.435798             0.503876  ...            0.666667    0.693150
25   0.474708             0.775194  ...            0.666667    0.693162
26   0.494163             0.860465  ...            0.666667    0.693152
27   0.505837             0.945736  ...            0.666667    0.693240
28   0.490272             0.968992  ...            0.666667    0.693256
29   0.470817             0.728682  ...            0.666667    0.693149
30   0.494163             0.922481  ...            0.666667    0.693219
31   0.451362             0.767442  ...            0.666667    0.693149
32   0.513619             0.767442  ...            0.666667    0.693156
33   0.544747             0.914729  ...            0.666667    0.693166
34   0.517510             0.798450  ...            0.666667    0.693171
35   0.505837             0.860465  ...            0.666667    0.693176
36   0.533074             0.821705  ...            0.666667    0.693158
37   0.521401             0.790698  ...            0.666667    0.693153
38   0.470817             0.713178  ...            0.666667    0.693197
39   0.529183             0.852713  ...            0.666667    0.693169
40   0.494163             0.790698  ...            0.666667    0.693168
41   0.466926             0.720930  ...            0.666667    0.693163
42   0.466926             0.829457  ...            0.666667    0.693177
43   0.505837             0.821705  ...            0.666667    0.693167
44   0.486381             0.751938  ...            0.666667    0.693160
45   0.498054             0.883721  ...            0.666667    0.693198
46   0.470817             0.860465  ...            0.666667    0.693187
47   0.505837             0.899225  ...            0.666667    0.693188
48   0.482490             0.860465  ...            0.666667    0.693189
49   0.463035             0.844961  ...            0.666667    0.693181

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.491525                 1.0                  0.0      0.659091
TestLoader Losses 0.6933203268859346
@@@@ individuo =  0 [list([3]) list([5]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.4915254237288136
result (0, 0.4915254237288136)
result (1, 0.8135593220338984)
result (2, 0.7288135593220338)
result (3, 0.8305084745762712)
result (4, 0.7966101694915254)
result (5, 0.7627118644067796)
result (6, 0.847457627118644)
result (7, 0.7796610169491526)
result (8, 0.8305084745762712)
result (9, 0.7966101694915254)


 Saving new generated items of geração  2

individuo [list([3]) list([5]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114]) 


individuo [list([5]) list([4]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12]) 


individuo [list([4]) list([2]) list([0, 11]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2]) 


individuo [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([3], [5], [1, 7]) 


individuo [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 7]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12]) 


individuo [list([3]) list([5]) list([1, 7]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([3], [5], [1, 7], [1, 0.5950958103579727], [1, 7], [1, 0.42282557555718114]) 


individuo [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([1, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([3], [5], [1, 7]) 


individuo [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 7], [1, 0.42282557555718114]) 



@@@@ Reinsercao

cacheStore =  {'([4], [3], [1, 5], [1, 0.1262070664185572], [1, 5])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.847457627118644, '([5], [4], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [2], [1, 3], [1, 4], [1, 4])': 0.7288135593220338, '([2], [1], [1, 9], [1, 0.17065736910750998], [1, 11], [1, 0.3197351493711345], [1, 11], [1, 0.5177330618879615], [1, 9], [1, 3], [1, 0.27610931992185345])': 0.5084745762711864, '([3], [5], [1, 8], [1, 10])': 0.7457627118644068, '([2], [6], [1, 8])': 0.7796610169491526, '([1], [4], [1, 5], [1, 12])': 0.5084745762711864, '([1], [4], [1, 4], [1, 0.5131789330011404])': 0.4915254237288136, '([1], [6], [1, 5], [1, 7], [1, 0.06254698615663809])': 0.5084745762711864, '([4], [2], [1, 3], [1, 12])': 0.7966101694915254, '([3], [5], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4])': 0.8135593220338984, '([5], [4], [1, 8], [1, 10])': 0.8305084745762712, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.2574753409377971], [1, 4], [1, 4])': 0.6440677966101694, '([4], [2], [1, 3], [1, 5])': 0.7796610169491526, '([4], [3], [1, 12])': 0.7627118644067796, '([3], [5])': 0.8305084745762712, '([3], [5], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.8135593220338984, '([4], [2], [1, 7], [1, 0.12676812206472354])': 0.8135593220338984, '([4], [2], [1, 3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.6610169491525424, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.12676812206472354])': 0.864406779661017, '([4], [3], [1, 7], [1, 0.12676812206472354])': 0.7966101694915254, '([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.8135593220338984, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([4], [2])': 0.7288135593220338, '([3], [5], [1, 7])': 0.8305084745762712, '([4], [2], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 7])': 0.7627118644067796, '([3], [5], [1, 7], [1, 0.5950958103579727], [1, 7], [1, 0.42282557555718114])': 0.7796610169491526}


 $$$$$$$$ Geração  3
population =  [[list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([0, 10])
  list([1, 0.15153638994891563]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([0, 10])
  list([1, 0.15153638994891563]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([5]) list([4]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
  list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
  list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([3]) list([5]) list([1, 7]) list([1, 0.5950958103579727])
  list([0, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([1, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([0, 10])
  list([1, 0.15153638994891563]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([4]) list([2]) list([0, 11]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([0, 10])
  list([1, 0.15153638994891563]) list([0, 3])
  list([0, 0.18389479625169752])]]
populationFitness =  [0.86440678 0.84745763 0.83050847 0.83050847 0.81355932 0.79661017
 0.79661017 0.77966102 0.76271186 0.72881356]
bestParent, bestParentFitness [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])] 0.864406779661017


@@@@ Selecao
indexParent 5
indexParent 7
indexParent 1
indexParent 3
indexParent 4
indexParent 0
indexParent 2
indexParent 5
indexParent 6
indexParent 1


@@@@ Crossover
crossoverPoint 9
crossoverPoint 2
crossoverPoint 4
not changing individuals
crossoverPoint 9


@@@@ Mutacao
Individuos para mutacao [4, 3]
@@@ mutated [1, 10]
@@@ mutated [0, 0.15153638994891563]


@@@@ Calculando fitness
verifyEntry ([4], [2], [1, 10])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=1024, bias=True)
  (1): ReLU()
  (2): Linear(in_features=1024, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.74 and acc: 45.00%
2814.69 total seconds elapsed. 140.73 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.583658             0.511628  ...            0.666667    0.976187
1    0.548638             0.589147  ...            0.150000    0.743013
2    0.653696             0.627907  ...            0.181818    0.767215
3    0.704280             0.689922  ...            0.514286    0.802169
4    0.723735             0.782946  ...            0.631579    0.883223
5    0.731518             0.751938  ...            0.433333    0.848544
6    0.669261             0.674419  ...            0.521739    0.882501
7    0.696498             0.643411  ...            0.421053    0.853918
8    0.754864             0.790698  ...            0.500000    0.896644
9    0.793774             0.806202  ...            0.217391    0.970072
10   0.750973             0.798450  ...            0.461538    0.932725
11   0.789883             0.798450  ...            0.586667    1.050127
12   0.774319             0.798450  ...            0.280000    1.006549
13   0.719844             0.697674  ...            0.609756    1.157042
14   0.797665             0.829457  ...            0.468750    0.961917
15   0.747082             0.658915  ...            0.592593    1.152637
16   0.871595             0.906977  ...            0.468750    0.997409
17   0.805447             0.806202  ...            0.461538    1.054227
18   0.832685             0.821705  ...            0.468750    1.072597
19   0.793774             0.798450  ...            0.547945    1.160084

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.728814            0.965517                  0.5      0.777778
TestLoader Losses 0.5555254342192311
@@@@ individuo =  4 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7288135593220338
verifyEntry ([4], [2], [1, 10], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=1024, bias=True)
  (1): ReLU()
  (2): Linear(in_features=1024, out_features=128, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.42282557555718114, inplace=False)
  (5): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.69 and acc: 45.00%
2816.34 total seconds elapsed. 140.82 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.498054             0.488372  ...            0.000000    0.693966
1    0.552529             0.457364  ...            0.658537    0.699266
2    0.599222             0.666667  ...            0.064516    0.713728
3    0.579767             0.441860  ...            0.444444    0.725702
4    0.731518             0.821705  ...            0.613333    0.753022
5    0.692607             0.612403  ...            0.594595    0.785880
6    0.743191             0.829457  ...            0.514286    0.823753
7    0.735409             0.759690  ...            0.419355    0.848204
8    0.750973             0.697674  ...            0.619048    1.047513
9    0.782101             0.798450  ...            0.575342    0.963373
10   0.778210             0.775194  ...            0.500000    0.956572
11   0.739300             0.790698  ...            0.631579    0.993627
12   0.754864             0.790698  ...            0.392857    0.884533
13   0.754864             0.767442  ...            0.477612    0.930700
14   0.813230             0.837209  ...            0.500000    1.027888
15   0.793774             0.759690  ...            0.500000    1.046382
16   0.813230             0.852713  ...            0.440678    1.013972
17   0.828794             0.790698  ...            0.535211    1.139503
18   0.832685             0.829457  ...            0.589744    1.266390
19   0.789883             0.782946  ...            0.440678    1.063000

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.694915            0.517241             0.866667         0.625
TestLoader Losses 0.5420968694201971
@@@@ individuo =  0 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.6949152542372882
verifyEntry ([4], [2], [1, 7])

achei cache 0.7627118644067796  individuo =  1 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7627118644067796
verifyEntry ([4], [2], [1, 10], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=1024, bias=True)
  (1): ReLU()
  (2): Linear(in_features=1024, out_features=128, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.42282557555718114, inplace=False)
  (5): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.69 and acc: 45.00%
2819.42 total seconds elapsed. 140.97 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.498054             0.488372  ...            0.000000    0.693966
1    0.552529             0.457364  ...            0.658537    0.699266
2    0.599222             0.666667  ...            0.064516    0.713728
3    0.579767             0.441860  ...            0.444444    0.725702
4    0.731518             0.821705  ...            0.613333    0.753022
5    0.692607             0.612403  ...            0.594595    0.785880
6    0.743191             0.829457  ...            0.514286    0.823753
7    0.735409             0.759690  ...            0.419355    0.848204
8    0.750973             0.697674  ...            0.619048    1.047513
9    0.782101             0.798450  ...            0.575342    0.963373
10   0.778210             0.775194  ...            0.500000    0.956572
11   0.739300             0.790698  ...            0.631579    0.993627
12   0.754864             0.790698  ...            0.392857    0.884533
13   0.754864             0.767442  ...            0.477612    0.930700
14   0.813230             0.837209  ...            0.500000    1.027888
15   0.793774             0.759690  ...            0.500000    1.046382
16   0.813230             0.852713  ...            0.440678    1.013972
17   0.828794             0.790698  ...            0.535211    1.139503
18   0.832685             0.829457  ...            0.589744    1.266390
19   0.789883             0.782946  ...            0.440678    1.063000

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.694915            0.517241             0.866667         0.625
TestLoader Losses 0.5420968694201971
@@@@ individuo =  8 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.6949152542372882
verifyEntry ([3], [5], [1, 7])

achei cache 0.8305084745762712  individuo =  3 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.8305084745762712
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=4096, bias=True)
  (8): ReLU()
  (9): Linear(in_features=4096, out_features=128, bias=True)
  (10): ReLU()
  (11): Dropout(p=0.42282557555718114, inplace=False)
  (12): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 45.00%
2866.52 total seconds elapsed. 143.33 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.525292             0.519380  ...            0.666667    0.693517
1    0.552529             0.767442  ...            0.674157    0.691812
2    0.579767             0.558140  ...            0.674157    0.719965
3    0.673152             0.728682  ...            0.615385    0.875460
4    0.700389             0.689922  ...            0.583333    0.913768
5    0.715953             0.736434  ...            0.392157    0.794813
6    0.708171             0.751938  ...            0.400000    0.922891
7    0.750973             0.736434  ...            0.426230    0.919713
8    0.754864             0.728682  ...            0.484848    1.050495
9    0.766537             0.790698  ...            0.384615    1.023730
10   0.747082             0.744186  ...            0.507463    0.882943
11   0.801556             0.860465  ...            0.437500    1.058669
12   0.793774             0.790698  ...            0.607595    1.120934
13   0.774319             0.798450  ...            0.507463    1.010826
14   0.692607             0.705426  ...            0.550725    0.811036
15   0.758755             0.860465  ...            0.521739    0.963429
16   0.840467             0.868217  ...            0.571429    1.223842
17   0.844358             0.906977  ...            0.529412    1.231761
18   0.813230             0.868217  ...            0.444444    1.128531
19   0.762646             0.782946  ...            0.492308    0.989401

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0   0.79661            0.793103                  0.8      0.793103
TestLoader Losses 0.42824699413978445
@@@@ individuo =  9 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7966101694915254
verifyEntry ([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=4096, bias=True)
  (8): ReLU()
  (9): Linear(in_features=4096, out_features=2, bias=True)
)

Best epoch: 21 with loss: 0.69 and acc: 50.00%
5252.39 total seconds elapsed. 105.05 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.490272             0.240310  ...            0.000000    0.695726
1    0.443580             0.333333  ...            0.000000    0.693158
2    0.486381             0.248062  ...            0.666667    0.693230
3    0.482490             0.713178  ...            0.000000    0.693165
4    0.439689             0.596899  ...            0.666667    0.693149
5    0.501946             1.000000  ...            0.666667    0.693209
6    0.501946             1.000000  ...            0.666667    0.693189
7    0.501946             1.000000  ...            0.666667    0.693171
8    0.501946             1.000000  ...            0.666667    0.693200
9    0.501946             1.000000  ...            0.666667    0.693159
10   0.501946             1.000000  ...            0.666667    0.693155
11   0.474708             0.744186  ...            0.666667    0.716518
12   0.501946             1.000000  ...            0.666667    0.693158
13   0.501946             1.000000  ...            0.666667    0.693183
14   0.501946             1.000000  ...            0.666667    0.693148
15   0.501946             1.000000  ...            0.666667    0.693157
16   0.501946             1.000000  ...            0.666667    0.693172
17   0.501946             1.000000  ...            0.666667    0.693148
18   0.455253             0.713178  ...            0.666667    0.693150
19   0.443580             0.178295  ...            0.000000    0.693148
20   0.490272             0.883721  ...            0.000000    0.693149
21   0.459144             0.263566  ...            0.666667    0.693147
22   0.498054             0.984496  ...            0.666667    0.693159
23   0.501946             1.000000  ...            0.666667    0.693158
24   0.501946             1.000000  ...            0.666667    0.693153
25   0.501946             1.000000  ...            0.666667    0.693166
26   0.501946             1.000000  ...            0.666667    0.693161
27   0.501946             1.000000  ...            0.666667    0.693154
28   0.501946             1.000000  ...            0.666667    0.693153
29   0.501946             0.379845  ...            0.666667    0.693158
30   0.482490             0.317829  ...            0.666667    0.693150
31   0.501946             1.000000  ...            0.666667    0.693177
32   0.424125             0.379845  ...            0.666667    0.693150
33   0.501946             1.000000  ...            0.666667    0.693160
34   0.501946             1.000000  ...            0.666667    0.693179
35   0.501946             1.000000  ...            0.666667    0.693154
36   0.501946             1.000000  ...            0.666667    0.693187
37   0.501946             1.000000  ...            0.666667    0.693161
38   0.501946             1.000000  ...            0.666667    0.693159
39   0.501946             1.000000  ...            0.666667    0.693163
40   0.501946             1.000000  ...            0.666667    0.693159
41   0.501946             1.000000  ...            0.666667    0.693172
42   0.501946             1.000000  ...            0.666667    0.693167
43   0.501946             1.000000  ...            0.666667    0.693164
44   0.501946             1.000000  ...            0.666667    0.693158
45   0.501946             1.000000  ...            0.666667    0.693156
46   0.501946             1.000000  ...            0.666667    0.693163
47   0.501946             1.000000  ...            0.666667    0.693166
48   0.501946             1.000000  ...            0.666667    0.693166
49   0.501946             1.000000  ...            0.666667    0.693173

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.491525                 1.0                  0.0      0.659091
TestLoader Losses 0.6932959142377821
@@@@ individuo =  6 [list([3]) list([5]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.4915254237288136
verifyEntry ([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=4096, bias=True)
  (8): ReLU()
  (9): Linear(in_features=4096, out_features=128, bias=True)
  (10): ReLU()
  (11): Dropout(p=0.42282557555718114, inplace=False)
  (12): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 43.33%
4489.52 total seconds elapsed. 112.24 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.486381             0.116279  ...            0.000000    0.692945
1    0.564202             0.263566  ...            0.520000    0.692337
2    0.525292             0.294574  ...            0.436364    0.692712
3    0.614786             0.496124  ...            0.500000    0.693086
4    0.552529             0.263566  ...            0.436364    0.693121
5    0.603113             0.449612  ...            0.555556    0.693517
6    0.653696             0.627907  ...            0.563380    0.693949
7    0.680934             0.697674  ...            0.392857    0.694728
8    0.630350             0.395349  ...            0.400000    0.696640
9    0.708171             0.736434  ...            0.440678    0.698173
10   0.634241             0.472868  ...            0.529412    0.703795
11   0.696498             0.813953  ...            0.515152    0.710178
12   0.665370             0.457364  ...            0.555556    0.725384
13   0.696498             0.666667  ...            0.560000    0.747561
14   0.700389             0.713178  ...            0.466667    0.754514
15   0.731518             0.775194  ...            0.571429    0.783084
16   0.750973             0.689922  ...            0.600000    0.846913
17   0.743191             0.860465  ...            0.413793    0.832685
18   0.723735             0.713178  ...            0.514286    0.876297
19   0.731518             0.821705  ...            0.413793    0.868799
20   0.731518             0.751938  ...            0.451613    0.875726
21   0.731518             0.728682  ...            0.444444    0.889615
22   0.770428             0.798450  ...            0.500000    0.931058
23   0.805447             0.798450  ...            0.500000    0.953644
24   0.766537             0.744186  ...            0.578947    1.008435
25   0.766537             0.806202  ...            0.535211    1.000380
26   0.766537             0.736434  ...            0.555556    1.006396
27   0.778210             0.829457  ...            0.468750    1.015301
28   0.821012             0.868217  ...            0.476190    1.010655
29   0.747082             0.682171  ...            0.571429    1.073828
30   0.848249             0.937984  ...            0.476190    1.056589
31   0.782101             0.759690  ...            0.540541    1.087699
32   0.832685             0.837209  ...            0.492754    1.081716
33   0.801556             0.821705  ...            0.468750    1.084541
34   0.793774             0.852713  ...            0.470588    1.096543
35   0.778210             0.767442  ...            0.470588    1.112160
36   0.785992             0.798450  ...            0.485714    1.139844
37   0.805447             0.806202  ...            0.451613    1.095308
38   0.836576             0.875969  ...            0.476190    1.119603
39   0.809339             0.806202  ...            0.514286    1.136373

[40 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0   0.79661            0.862069             0.733333      0.806452
TestLoader Losses 0.45988187850531886
@@@@ individuo =  2 [list([5]) list([4]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7966101694915254
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])

achei cache 0.847457627118644  individuo =  7 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.847457627118644
verifyEntry ([3], [5], [1, 7], [1, 0.5950958103579727], [1, 10], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.5950958103579727, inplace=False)
  (3): Linear(in_features=128, out_features=1024, bias=True)
  (4): ReLU()
  (5): Linear(in_features=1024, out_features=128, bias=True)
  (6): ReLU()
  (7): Dropout(p=0.42282557555718114, inplace=False)
  (8): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 35 with loss: 0.69 and acc: 50.00%
5118.66 total seconds elapsed. 102.37 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.466926             0.519380  ...            0.000000    0.717560
1    0.517510             0.612403  ...            0.666667    0.693160
2    0.494163             0.364341  ...            0.000000    0.694883
3    0.529183             0.341085  ...            0.666667    0.693356
4    0.517510             0.937984  ...            0.666667    0.693185
5    0.498054             0.759690  ...            0.666667    0.693166
6    0.501946             0.945736  ...            0.666667    0.693219
7    0.498054             0.806202  ...            0.666667    0.693178
8    0.435798             0.627907  ...            0.666667    0.693158
9    0.466926             0.813953  ...            0.666667    0.693177
10   0.494163             0.968992  ...            0.666667    0.693178
11   0.439689             0.813953  ...            0.666667    0.693163
12   0.498054             0.961240  ...            0.666667    0.693192
13   0.501946             1.000000  ...            0.666667    0.693183
14   0.501946             1.000000  ...            0.666667    0.693247
15   0.501946             1.000000  ...            0.666667    0.693206
16   0.501946             1.000000  ...            0.666667    0.693174
17   0.505837             1.000000  ...            0.666667    0.693183
18   0.513619             0.868217  ...            0.666667    0.693167
19   0.552529             0.759690  ...            0.666667    0.693324
20   0.498054             0.953488  ...            0.666667    0.693355
21   0.529183             0.992248  ...            0.620690    0.694016
22   0.501946             0.891473  ...            0.626506    0.694358
23   0.548638             0.798450  ...            0.620690    0.694042
24   0.564202             0.837209  ...            0.171429    0.695860
25   0.575875             0.837209  ...            0.064516    0.715754
26   0.568093             0.852713  ...            0.181818    0.709214
27   0.560311             0.860465  ...            0.575342    0.699427
28   0.622568             0.860465  ...            0.333333    0.726977
29   0.591440             0.906977  ...            0.604651    0.701036
30   0.533074             0.953488  ...            0.607595    0.703873
31   0.575875             0.914729  ...            0.529412    0.722535
32   0.583658             0.906977  ...            0.666667    0.695086
33   0.498054             0.984496  ...            0.666667    0.693717
34   0.501946             0.875969  ...            0.666667    0.693618
35   0.513619             0.705426  ...            0.666667    0.693148
36   0.509728             0.503876  ...            0.666667    0.693234
37   0.513619             0.759690  ...            0.666667    0.693225
38   0.466926             0.511628  ...            0.666667    0.693213
39   0.482490             0.813953  ...            0.666667    0.693263
40   0.447471             0.736434  ...            0.666667    0.693205
41   0.466926             0.689922  ...            0.666667    0.693312
42   0.447471             0.767442  ...            0.666667    0.693205
43   0.505837             0.922481  ...            0.666667    0.693355
44   0.482490             0.961240  ...            0.666667    0.693272
45   0.501946             1.000000  ...            0.666667    0.693279
46   0.501946             1.000000  ...            0.666667    0.693244
47   0.517510             0.875969  ...            0.666667    0.693189
48   0.533074             0.651163  ...            0.666667    0.693174
49   0.544747             0.728682  ...            0.666667    0.693171

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.491525                 1.0                  0.0      0.659091
TestLoader Losses 0.6932865108473826
@@@@ individuo =  5 [list([3]) list([5]) list([1, 7]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.4915254237288136
result (0, 0.6949152542372882)
result (1, 0.7627118644067796)
result (2, 0.7966101694915254)
result (3, 0.8305084745762712)
result (4, 0.7288135593220338)
result (5, 0.4915254237288136)
result (6, 0.4915254237288136)
result (7, 0.847457627118644)
result (8, 0.6949152542372882)
result (9, 0.7966101694915254)


 Saving new generated items of geração  3

individuo [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 10], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 7]) 


individuo [list([5]) list([4]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114]) 


individuo [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([3], [5], [1, 7]) 


individuo [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 10]) 


individuo [list([3]) list([5]) list([1, 7]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([3], [5], [1, 7], [1, 0.5950958103579727], [1, 10], [1, 7], [1, 0.42282557555718114]) 


individuo [list([3]) list([5]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12]) 


individuo [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 10], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114]) 



@@@@ Reinsercao

cacheStore =  {'([4], [3], [1, 5], [1, 0.1262070664185572], [1, 5])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.847457627118644, '([5], [4], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [2], [1, 3], [1, 4], [1, 4])': 0.7288135593220338, '([2], [1], [1, 9], [1, 0.17065736910750998], [1, 11], [1, 0.3197351493711345], [1, 11], [1, 0.5177330618879615], [1, 9], [1, 3], [1, 0.27610931992185345])': 0.5084745762711864, '([3], [5], [1, 8], [1, 10])': 0.7457627118644068, '([2], [6], [1, 8])': 0.7796610169491526, '([1], [4], [1, 5], [1, 12])': 0.5084745762711864, '([1], [4], [1, 4], [1, 0.5131789330011404])': 0.4915254237288136, '([1], [6], [1, 5], [1, 7], [1, 0.06254698615663809])': 0.5084745762711864, '([4], [2], [1, 3], [1, 12])': 0.7966101694915254, '([3], [5], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4])': 0.8135593220338984, '([5], [4], [1, 8], [1, 10])': 0.8305084745762712, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.2574753409377971], [1, 4], [1, 4])': 0.6440677966101694, '([4], [2], [1, 3], [1, 5])': 0.7796610169491526, '([4], [3], [1, 12])': 0.7627118644067796, '([3], [5])': 0.8305084745762712, '([3], [5], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.8135593220338984, '([4], [2], [1, 7], [1, 0.12676812206472354])': 0.8135593220338984, '([4], [2], [1, 3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.6610169491525424, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.12676812206472354])': 0.864406779661017, '([4], [3], [1, 7], [1, 0.12676812206472354])': 0.7966101694915254, '([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.8135593220338984, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([4], [2])': 0.7288135593220338, '([3], [5], [1, 7])': 0.8305084745762712, '([4], [2], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 7])': 0.7627118644067796, '([3], [5], [1, 7], [1, 0.5950958103579727], [1, 7], [1, 0.42282557555718114])': 0.7796610169491526, '([4], [2], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.6949152542372882, '([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 10])': 0.7288135593220338, '([3], [5], [1, 7], [1, 0.5950958103579727], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.4915254237288136, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254}


 $$$$$$$$ Geração  4
population =  [[list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([0, 10])
  list([0, 0.15153638994891563]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([5]) list([4]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.43531701384079674]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 12])
  list([0, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([0, 10])
  list([0, 0.15153638994891563]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([3]) list([5]) list([1, 7]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]]
populationFitness =  [0.86440678 0.84745763 0.83050847 0.79661017 0.79661017 0.76271186
 0.72881356 0.69491525 0.69491525 0.49152542]
bestParent, bestParentFitness [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 12])
 list([0, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])] 0.864406779661017


@@@@ Selecao
indexParent 4
indexParent 0
indexParent 7
indexParent 1
indexParent 2
indexParent 8
indexParent 4
indexParent 8
indexParent 5
indexParent 6


@@@@ Crossover
crossoverPoint 3
crossoverPoint 5
crossoverPoint 7
not changing individuals
not changing individuals


@@@@ Mutacao
Individuos para mutacao [0, 1]
@@@ mutated [1, 6]
@@@ mutated [1, 0.43531701384079674]


@@@@ Calculando fitness
verifyEntry ([4], [2], [1, 10])

achei cache 0.7288135593220338  individuo =  7 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7288135593220338
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Linear(in_features=1024, out_features=128, bias=True)
  (5): ReLU()
  (6): Dropout(p=0.42282557555718114, inplace=False)
  (7): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 45.00%
2920.83 total seconds elapsed. 146.04 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.521401             0.883721  ...            0.448276    0.694443
1    0.455253             0.581395  ...            0.190476    0.693443
2    0.587549             0.341085  ...            0.440678    0.697024
3    0.638132             0.565891  ...            0.339623    0.707181
4    0.622568             0.620155  ...            0.521739    0.726428
5    0.634241             0.643411  ...            0.000000    0.779871
6    0.622568             0.635659  ...            0.244898    0.762692
7    0.653696             0.589147  ...            0.575342    0.786664
8    0.731518             0.782946  ...            0.535211    0.818811
9    0.688716             0.612403  ...            0.430769    0.844461
10   0.750973             0.775194  ...            0.437500    0.895012
11   0.758755             0.767442  ...            0.594595    0.965916
12   0.770428             0.782946  ...            0.529412    0.959806
13   0.754864             0.767442  ...            0.555556    1.012460
14   0.735409             0.790698  ...            0.384615    1.022501
15   0.782101             0.759690  ...            0.419355    1.008852
16   0.824903             0.868217  ...            0.542857    1.091108
17   0.840467             0.860465  ...            0.542857    1.183636
18   0.793774             0.790698  ...            0.529412    1.149371
19   0.770428             0.790698  ...            0.571429    1.181444

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.728814            0.965517                  0.5      0.777778
TestLoader Losses 0.5401265843439911
@@@@ individuo =  6 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7288135593220338
verifyEntry ([4], [2], [1, 7])

achei cache 0.7627118644067796  individuo =  4 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7627118644067796
verifyEntry ([4], [2], [1, 10], [1, 7], [1, 0.42282557555718114])

achei cache 0.6949152542372882  individuo =  8 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.6949152542372882
verifyEntry ([4], [2], [1, 10])

achei cache 0.7288135593220338  individuo =  9 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7288135593220338
verifyEntry ([4], [2], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=1024, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.1857731567558439, inplace=False)
  (3): Linear(in_features=1024, out_features=2048, bias=True)
  (4): ReLU()
  (5): Linear(in_features=2048, out_features=64, bias=True)
  (6): ReLU()
  (7): Dropout(p=0.43531701384079674, inplace=False)
  (8): Linear(in_features=64, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.70 and acc: 43.33%
2925.53 total seconds elapsed. 146.28 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.466926             0.527132  ...            0.666667    0.695299
1    0.571984             0.782946  ...            0.000000    0.702156
2    0.583658             0.434109  ...            0.666667    0.739647
3    0.622568             0.689922  ...            0.363636    0.736121
4    0.708171             0.705426  ...            0.555556    0.784976
5    0.657588             0.705426  ...            0.461538    0.803309
6    0.739300             0.720930  ...            0.357143    0.851127
7    0.727626             0.728682  ...            0.555556    0.916028
8    0.747082             0.728682  ...            0.620690    1.171935
9    0.673152             0.728682  ...            0.634146    0.893728
10   0.766537             0.775194  ...            0.594595    1.022571
11   0.747082             0.720930  ...            0.451613    0.942082
12   0.766537             0.713178  ...            0.440678    1.002246
13   0.793774             0.813953  ...            0.500000    1.057892
14   0.793774             0.806202  ...            0.507937    1.081980
15   0.863813             0.860465  ...            0.484848    1.259924
16   0.797665             0.790698  ...            0.563380    1.187839
17   0.840467             0.852713  ...            0.507937    1.279651
18   0.840467             0.844961  ...            0.492308    1.172768
19   0.766537             0.751938  ...            0.320000    1.090856

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.644068             0.37931                  0.9      0.511628
TestLoader Losses 0.5726298043283365
@@@@ individuo =  1 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 6])
 list([1, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.6440677966101694
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=64, bias=True)
  (8): ReLU()
  (9): Linear(in_features=64, out_features=128, bias=True)
  (10): ReLU()
  (11): Dropout(p=0.42282557555718114, inplace=False)
  (12): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 46.67%
2931.60 total seconds elapsed. 146.58 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.501946             1.000000  ...            0.666667    0.694779
1    0.494163             0.511628  ...            0.658824    0.694136
2    0.505837             0.720930  ...            0.666667    0.695628
3    0.661479             0.806202  ...            0.062500    0.703896
4    0.618677             0.410853  ...            0.642857    0.707788
5    0.673152             0.689922  ...            0.615385    0.741211
6    0.708171             0.705426  ...            0.437500    0.793227
7    0.700389             0.635659  ...            0.605263    0.876911
8    0.778210             0.782946  ...            0.500000    1.001067
9    0.750973             0.767442  ...            0.426230    1.052815
10   0.785992             0.798450  ...            0.521739    1.078892
11   0.743191             0.813953  ...            0.594595    0.976481
12   0.805447             0.813953  ...            0.625000    1.072690
13   0.797665             0.813953  ...            0.552632    1.087234
14   0.817121             0.829457  ...            0.468750    1.149540
15   0.836576             0.875969  ...            0.507463    1.168190
16   0.793774             0.813953  ...            0.461538    1.169925
17   0.836576             0.875969  ...            0.468750    1.251210
18   0.828794             0.844961  ...            0.521739    1.326930
19   0.840467             0.844961  ...            0.578947    1.370856

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.728814            0.931034             0.533333      0.771429
TestLoader Losses 0.5695161364846311
@@@@ individuo =  5 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 6])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7288135593220338
verifyEntry ([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Linear(in_features=128, out_features=128, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.42282557555718114, inplace=False)
  (5): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.71 and acc: 43.33%
5047.16 total seconds elapsed. 100.94 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.478599             0.449612  ...            0.666667    0.737922
1    0.556420             0.651163  ...            0.635294    0.705033
2    0.642023             0.689922  ...            0.627907    0.766723
3    0.735409             0.813953  ...            0.250000    0.824773
4    0.708171             0.666667  ...            0.514286    0.864599
5    0.735409             0.790698  ...            0.521739    0.951432
6    0.774319             0.790698  ...            0.521739    1.032681
7    0.770428             0.821705  ...            0.421053    1.009317
8    0.774319             0.736434  ...            0.392857    0.946873
9    0.774319             0.798450  ...            0.483871    0.995005
10   0.778210             0.759690  ...            0.555556    1.112435
11   0.789883             0.790698  ...            0.547945    1.093717
12   0.727626             0.767442  ...            0.285714    0.976554
13   0.793774             0.775194  ...            0.492308    1.122736
14   0.809339             0.798450  ...            0.589744    1.312102
15   0.836576             0.883721  ...            0.483871    1.171752
16   0.813230             0.775194  ...            0.440678    1.027607
17   0.840467             0.852713  ...            0.448276    1.082701
18   0.828794             0.837209  ...            0.597015    1.108275
19   0.859922             0.844961  ...            0.558824    1.254855
20   0.871595             0.837209  ...            0.540541    1.481968
21   0.805447             0.829457  ...            0.291667    1.025048
22   0.789883             0.767442  ...            0.578947    1.170845
23   0.863813             0.852713  ...            0.520548    1.598935
24   0.875486             0.914729  ...            0.413793    1.348884
25   0.793774             0.767442  ...            0.555556    1.197732
26   0.859922             0.860465  ...            0.459016    1.488120
27   0.805447             0.883721  ...            0.428571    1.295786
28   0.828794             0.775194  ...            0.500000    1.240426
29   0.859922             0.906977  ...            0.413793    1.485645
30   0.809339             0.829457  ...            0.542857    1.334456
31   0.875486             0.883721  ...            0.459016    1.312923
32   0.832685             0.852713  ...            0.483871    1.321280
33   0.891051             0.899225  ...            0.492754    1.739747
34   0.863813             0.868217  ...            0.280000    1.313573
35   0.840467             0.798450  ...            0.533333    1.645567
36   0.867704             0.852713  ...            0.459016    1.554081
37   0.902724             0.914729  ...            0.535211    1.703510
38   0.867704             0.868217  ...            0.476190    1.584561
39   0.840467             0.891473  ...            0.483871    1.327391
40   0.914397             0.914729  ...            0.483871    1.467687
41   0.859922             0.860465  ...            0.459016    1.331956
42   0.863813             0.852713  ...            0.483871    1.594577
43   0.852140             0.868217  ...            0.454545    1.479191
44   0.887160             0.883721  ...            0.500000    1.667177
45   0.867704             0.868217  ...            0.468750    1.640840
46   0.840467             0.844961  ...            0.468750    1.199129
47   0.863813             0.868217  ...            0.463768    1.558638
48   0.879377             0.883721  ...            0.470588    1.621946
49   0.852140             0.868217  ...            0.484848    1.603974

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.779661            0.931034             0.633333       0.80597
TestLoader Losses 0.5309160589161566
@@@@ individuo =  2 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7796610169491526
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=64, bias=True)
  (8): ReLU()
  (9): Linear(in_features=64, out_features=128, bias=True)
  (10): ReLU()
  (11): Dropout(p=0.42282557555718114, inplace=False)
  (12): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 46.67%
2933.29 total seconds elapsed. 146.66 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.501946             1.000000  ...            0.666667    0.694779
1    0.494163             0.511628  ...            0.658824    0.694136
2    0.505837             0.720930  ...            0.666667    0.695628
3    0.661479             0.806202  ...            0.062500    0.703896
4    0.618677             0.410853  ...            0.642857    0.707788
5    0.673152             0.689922  ...            0.615385    0.741211
6    0.708171             0.705426  ...            0.437500    0.793227
7    0.700389             0.635659  ...            0.605263    0.876911
8    0.778210             0.782946  ...            0.500000    1.001067
9    0.750973             0.767442  ...            0.426230    1.052815
10   0.785992             0.798450  ...            0.521739    1.078892
11   0.743191             0.813953  ...            0.594595    0.976481
12   0.805447             0.813953  ...            0.625000    1.072690
13   0.797665             0.813953  ...            0.552632    1.087234
14   0.817121             0.829457  ...            0.468750    1.149540
15   0.836576             0.875969  ...            0.507463    1.168190
16   0.793774             0.813953  ...            0.461538    1.169925
17   0.836576             0.875969  ...            0.468750    1.251210
18   0.828794             0.844961  ...            0.521739    1.326930
19   0.840467             0.844961  ...            0.578947    1.370856

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.728814            0.931034             0.533333      0.771429
TestLoader Losses 0.5695161364846311
@@@@ individuo =  3 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 6])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7288135593220338
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=64, bias=True)
  (8): ReLU()
  (9): Dropout(p=0.43531701384079674, inplace=False)
  (10): Linear(in_features=64, out_features=128, bias=True)
  (11): ReLU()
  (12): Dropout(p=0.42282557555718114, inplace=False)
  (13): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.69 and acc: 40.00%
2933.96 total seconds elapsed. 146.70 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.498054             0.992248  ...            0.666667    0.695529
1    0.498054             0.821705  ...            0.666667    0.693022
2    0.509728             0.790698  ...            0.666667    0.694340
3    0.556420             0.697674  ...            0.641026    0.693836
4    0.575875             0.651163  ...            0.205128    0.696795
5    0.626459             0.658915  ...            0.285714    0.702818
6    0.634241             0.581395  ...            0.641026    0.704060
7    0.723735             0.651163  ...            0.521739    0.732451
8    0.704280             0.782946  ...            0.477612    0.772955
9    0.704280             0.697674  ...            0.433333    0.826689
10   0.731518             0.705426  ...            0.641026    0.836904
11   0.719844             0.852713  ...            0.451613    0.825864
12   0.785992             0.798450  ...            0.641026    0.904031
13   0.712062             0.837209  ...            0.542857    0.911041
14   0.770428             0.775194  ...            0.529412    0.898756
15   0.762646             0.798450  ...            0.535211    0.953310
16   0.821012             0.875969  ...            0.550725    1.060094
17   0.789883             0.813953  ...            0.578947    1.059186
18   0.739300             0.775194  ...            0.492308    0.976162
19   0.797665             0.821705  ...            0.400000    1.067448

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.745763            0.586207                  0.9      0.693878
TestLoader Losses 0.4747245139994864
@@@@ individuo =  0 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 6])
 list([1, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7457627118644068
result (0, 0.7457627118644068)
result (1, 0.6440677966101694)
result (2, 0.7796610169491526)
result (3, 0.7288135593220338)
result (4, 0.7627118644067796)
result (5, 0.7288135593220338)
result (6, 0.7288135593220338)
result (7, 0.7288135593220338)
result (8, 0.6949152542372882)
result (9, 0.7288135593220338)


 Saving new generated items of geração  4

individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 6])
 list([1, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 6])
 list([1, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674]) 


individuo [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 6])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 7]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 6])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.15153638994891563]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 10]) 


individuo [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.15153638994891563]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 10], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.38275251356251844]) list([0, 10])
 list([1, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([4], [2], [1, 10]) 



@@@@ Reinsercao

cacheStore =  {'([4], [3], [1, 5], [1, 0.1262070664185572], [1, 5])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.847457627118644, '([5], [4], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [2], [1, 3], [1, 4], [1, 4])': 0.7288135593220338, '([2], [1], [1, 9], [1, 0.17065736910750998], [1, 11], [1, 0.3197351493711345], [1, 11], [1, 0.5177330618879615], [1, 9], [1, 3], [1, 0.27610931992185345])': 0.5084745762711864, '([3], [5], [1, 8], [1, 10])': 0.7457627118644068, '([2], [6], [1, 8])': 0.7796610169491526, '([1], [4], [1, 5], [1, 12])': 0.5084745762711864, '([1], [4], [1, 4], [1, 0.5131789330011404])': 0.4915254237288136, '([1], [6], [1, 5], [1, 7], [1, 0.06254698615663809])': 0.5084745762711864, '([4], [2], [1, 3], [1, 12])': 0.7966101694915254, '([3], [5], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4])': 0.8135593220338984, '([5], [4], [1, 8], [1, 10])': 0.8305084745762712, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.2574753409377971], [1, 4], [1, 4])': 0.6440677966101694, '([4], [2], [1, 3], [1, 5])': 0.7796610169491526, '([4], [3], [1, 12])': 0.7627118644067796, '([3], [5])': 0.8305084745762712, '([3], [5], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.8135593220338984, '([4], [2], [1, 7], [1, 0.12676812206472354])': 0.8135593220338984, '([4], [2], [1, 3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.6610169491525424, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.12676812206472354])': 0.864406779661017, '([4], [3], [1, 7], [1, 0.12676812206472354])': 0.7966101694915254, '([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.8135593220338984, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([4], [2])': 0.7288135593220338, '([3], [5], [1, 7])': 0.8305084745762712, '([4], [2], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 7])': 0.7627118644067796, '([3], [5], [1, 7], [1, 0.5950958103579727], [1, 7], [1, 0.42282557555718114])': 0.7796610169491526, '([4], [2], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.6949152542372882, '([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 10])': 0.7288135593220338, '([3], [5], [1, 7], [1, 0.5950958103579727], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.4915254237288136, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])': 0.7457627118644068, '([4], [2], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674])': 0.6440677966101694, '([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114])': 0.7796610169491526, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])': 0.7288135593220338, '([4], [2], [1, 5], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.7288135593220338}


 $$$$$$$$ Geração  5
population =  [[list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 6])
  list([1, 0.43531701384079674]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.5465119394359016]) list([0, 10])
  list([0, 0.15153638994891563]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 6])
  list([1, 0.43531701384079674]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 6])
  list([0, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.39429564271574447]) list([1, 6])
  list([0, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.5465119394359016]) list([0, 10])
  list([0, 0.15153638994891563]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([1, 0.43531701384079674]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([4]) list([2]) list([0, 11]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.15153638994891563]) list([1, 7])
  list([1, 0.42282557555718114])]]
populationFitness =  [0.86440678 0.77966102 0.76271186 0.74576271 0.72881356 0.72881356
 0.72881356 0.72881356 0.72881356 0.69491525]
bestParent, bestParentFitness [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.39429564271574447]) list([1, 6])
 list([1, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])] 0.864406779661017


@@@@ Selecao
indexParent 5
indexParent 1
indexParent 0
indexParent 1
indexParent 4
indexParent 0
indexParent 7
indexParent 1
indexParent 4
indexParent 1


@@@@ Crossover
not changing individuals
crossoverPoint 5
not changing individuals
crossoverPoint 2
crossoverPoint 2


@@@@ Mutacao
Individuos para mutacao [5, 9]
@@@ mutated [0, 0.11817163662579326]
@@@ mutated [0, 0.5446961484005021]


@@@@ Calculando fitness
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])

achei cache 0.7288135593220338  individuo =  0 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([0, 0.11817163662579326])
 list([1, 7]) list([1, 0.42282557555718114])] 
 fitness =  0.7288135593220338
verifyEntry ([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Linear(in_features=2048, out_features=64, bias=True)
  (8): ReLU()
  (9): Linear(in_features=64, out_features=128, bias=True)
  (10): ReLU()
  (11): Dropout(p=0.42282557555718114, inplace=False)
  (12): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 20 with loss: 0.69 and acc: 50.00%
4892.16 total seconds elapsed. 97.84 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.513619             0.728682  ...            0.666667    0.695046
1    0.490272             0.674419  ...            0.666667    0.693467
2    0.443580             0.674419  ...            0.666667    0.694038
3    0.501946             0.976744  ...            0.666667    0.693683
4    0.478599             0.658915  ...            0.666667    0.693165
5    0.509728             0.883721  ...            0.666667    0.693370
6    0.501946             0.550388  ...            0.666667    0.693150
7    0.494163             0.697674  ...            0.666667    0.693228
8    0.513619             0.627907  ...            0.666667    0.693155
9    0.517510             0.604651  ...            0.666667    0.693199
10   0.490272             0.612403  ...            0.666667    0.693166
11   0.463035             0.666667  ...            0.666667    0.693237
12   0.486381             0.697674  ...            0.666667    0.693182
13   0.486381             0.480620  ...            0.000000    0.693147
14   0.513619             0.689922  ...            0.666667    0.693204
15   0.478599             0.643411  ...            0.666667    0.693209
16   0.490272             0.798450  ...            0.666667    0.693219
17   0.509728             0.674419  ...            0.666667    0.693174
18   0.529183             0.620155  ...            0.666667    0.693157
19   0.474708             0.403101  ...            0.000000    0.693172
20   0.486381             0.465116  ...            0.666667    0.693147
21   0.521401             0.581395  ...            0.666667    0.693157
22   0.540856             0.573643  ...            0.666667    0.693170
23   0.490272             0.713178  ...            0.666667    0.693240
24   0.501946             0.682171  ...            0.666667    0.693169
25   0.501946             0.496124  ...            0.666667    0.693148
26   0.529183             0.573643  ...            0.666667    0.693150
27   0.494163             0.534884  ...            0.666667    0.693148
28   0.486381             0.604651  ...            0.666667    0.693147
29   0.498054             0.480620  ...            0.666667    0.693151
30   0.474708             0.643411  ...            0.666667    0.693198
31   0.482490             0.689922  ...            0.666667    0.693162
32   0.509728             0.627907  ...            0.666667    0.693157
33   0.544747             0.596899  ...            0.666667    0.693165
34   0.501946             0.573643  ...            0.666667    0.693189
35   0.470817             0.472868  ...            0.000000    0.693163
36   0.501946             0.612403  ...            0.666667    0.693180
37   0.470817             0.744186  ...            0.666667    0.693189
38   0.513619             0.658915  ...            0.666667    0.693165
39   0.470817             0.488372  ...            0.666667    0.693151
40   0.466926             0.643411  ...            0.666667    0.693226
41   0.494163             0.612403  ...            0.666667    0.693156
42   0.521401             0.596899  ...            0.666667    0.693181
43   0.521401             0.596899  ...            0.666667    0.693148
44   0.466926             0.558140  ...            0.666667    0.693155
45   0.482490             0.302326  ...            0.000000    0.693260
46   0.494163             0.550388  ...            0.666667    0.693195
47   0.517510             0.589147  ...            0.666667    0.693153
48   0.521401             0.674419  ...            0.666667    0.693241
49   0.459144             0.620155  ...            0.666667    0.693169

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.491525                 1.0                  0.0      0.659091
TestLoader Losses 0.6932798654346143
@@@@ individuo =  9 [list([3]) list([5]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([0, 0.11817163662579326])
 list([1, 7]) list([1, 0.42282557555718114])] 
 fitness =  0.4915254237288136
verifyEntry ([3], [5], [1, 7], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Linear(in_features=128, out_features=2048, bias=True)
  (3): ReLU()
  (4): Linear(in_features=2048, out_features=64, bias=True)
  (5): ReLU()
  (6): Dropout(p=0.43531701384079674, inplace=False)
  (7): Linear(in_features=64, out_features=128, bias=True)
  (8): ReLU()
  (9): Dropout(p=0.42282557555718114, inplace=False)
  (10): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 9 with loss: 0.69 and acc: 50.00%
4883.69 total seconds elapsed. 97.67 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.517510             0.271318  ...            0.000000    0.693964
1    0.490272             0.100775  ...            0.000000    0.693556
2    0.451362             0.186047  ...            0.000000    0.693147
3    0.513619             0.302326  ...            0.000000    0.693174
4    0.540856             0.573643  ...            0.666667    0.693695
5    0.490272             0.488372  ...            0.666667    0.693159
6    0.451362             0.387597  ...            0.666667    0.693150
7    0.412451             0.302326  ...            0.666667    0.693149
8    0.431907             0.519380  ...            0.666667    0.693185
9    0.513619             0.465116  ...            0.000000    0.693147
10   0.509728             0.550388  ...            0.666667    0.693148
11   0.494163             0.558140  ...            0.666667    0.693164
12   0.486381             0.519380  ...            0.666667    0.693245
13   0.486381             0.596899  ...            0.666667    0.693186
14   0.451362             0.387597  ...            0.000000    0.693152
15   0.490272             0.434109  ...            0.666667    0.693148
16   0.536965             0.635659  ...            0.666667    0.693295
17   0.428016             0.480620  ...            0.000000    0.693148
18   0.478599             0.178295  ...            0.000000    0.693263
19   0.478599             0.201550  ...            0.000000    0.693253
20   0.486381             0.054264  ...            0.000000    0.693351
21   0.451362             0.201550  ...            0.000000    0.693210
22   0.498054             0.333333  ...            0.000000    0.693159
23   0.529183             0.302326  ...            0.000000    0.693193
24   0.459144             0.387597  ...            0.000000    0.693147
25   0.482490             0.596899  ...            0.666667    0.693161
26   0.455253             0.333333  ...            0.000000    0.693197
27   0.505837             0.372093  ...            0.666667    0.693153
28   0.474708             0.527132  ...            0.666667    0.693160
29   0.439689             0.565891  ...            0.000000    0.693149
30   0.517510             0.573643  ...            0.666667    0.693187
31   0.509728             0.705426  ...            0.666667    0.693176
32   0.486381             0.643411  ...            0.666667    0.693160
33   0.459144             0.565891  ...            0.666667    0.693155
34   0.486381             0.666667  ...            0.666667    0.693166
35   0.494163             0.658915  ...            0.666667    0.693169
36   0.463035             0.697674  ...            0.666667    0.693199
37   0.416342             0.387597  ...            0.000000    0.693149
38   0.482490             0.697674  ...            0.666667    0.693263
39   0.498054             0.813953  ...            0.666667    0.693176
40   0.494163             0.620155  ...            0.666667    0.693150
41   0.498054             0.465116  ...            0.666667    0.693147
42   0.494163             0.341085  ...            0.000000    0.693177
43   0.435798             0.395349  ...            0.000000    0.693147
44   0.540856             0.565891  ...            0.666667    0.693154
45   0.521401             0.496124  ...            0.000000    0.693147
46   0.463035             0.286822  ...            0.000000    0.693149
47   0.525292             0.542636  ...            0.666667    0.693147
48   0.478599             0.689922  ...            0.666667    0.693195
49   0.509728             0.705426  ...            0.666667    0.693155

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.491525                 1.0                  0.0      0.659091
TestLoader Losses 0.6932197647579645
@@@@ individuo =  6 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([1, 0.43531701384079674])
 list([1, 7]) list([1, 0.42282557555718114])] 
 fitness =  0.4915254237288136
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])

achei cache 0.7457627118644068  individuo =  7 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([1, 0.43531701384079674])
 list([1, 7]) list([1, 0.42282557555718114])] 
 fitness =  0.7457627118644068
verifyEntry ([4], [2], [1, 7], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Linear(in_features=128, out_features=128, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.42282557555718114, inplace=False)
  (5): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.70 and acc: 48.33%
2290.08 total seconds elapsed. 114.50 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.494163             0.325581  ...            0.650000    0.697711
1    0.607004             0.852713  ...            0.280000    0.700665
2    0.599222             0.565891  ...            0.142857    0.704401
3    0.607004             0.666667  ...            0.095238    0.718088
4    0.595331             0.426357  ...            0.620690    0.733865
5    0.680934             0.751938  ...            0.424242    0.729718
6    0.708171             0.674419  ...            0.372881    0.738358
7    0.657588             0.705426  ...            0.357143    0.753336
8    0.727626             0.666667  ...            0.623377    0.783306
9    0.704280             0.713178  ...            0.451613    0.780501
10   0.688716             0.728682  ...            0.313725    0.798534
11   0.595331             0.627907  ...            0.100000    0.832789
12   0.696498             0.651163  ...            0.535211    0.820893
13   0.739300             0.705426  ...            0.385965    0.832189
14   0.770428             0.767442  ...            0.575342    0.869932
15   0.766537             0.736434  ...            0.617284    0.960435
16   0.766537             0.852713  ...            0.357143    0.869218
17   0.719844             0.744186  ...            0.291667    0.905230
18   0.762646             0.767442  ...            0.468750    0.885183
19   0.785992             0.759690  ...            0.607595    1.017212

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.661017                 1.0             0.333333       0.74359
TestLoader Losses 0.5740311635752856
@@@@ individuo =  3 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.11817163662579326]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.6610169491525424
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])

achei cache 0.7288135593220338  individuo =  2 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([0, 0.11817163662579326])
 list([1, 7]) list([1, 0.42282557555718114])] 
 fitness =  0.7288135593220338
verifyEntry ([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114])

achei cache 0.7796610169491526  individuo =  5 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.11817163662579326]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7796610169491526
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 7], [1, 0.42282557555718114])

achei cache 0.7288135593220338  individuo =  1 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.11817163662579326]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7288135593220338
verifyEntry ([3], [5], [1, 10])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=1024, bias=True)
  (1): ReLU()
  (2): Linear(in_features=1024, out_features=2, bias=True)
)

Best epoch: 6 with loss: 0.73 and acc: 45.00%
4871.97 total seconds elapsed. 97.44 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.548638             0.558140  ...            0.666667    1.018638
1    0.649805             0.635659  ...            0.666667    1.169383
2    0.622568             0.643411  ...            0.515152    0.800983
3    0.731518             0.744186  ...            0.484848    0.910710
4    0.782101             0.806202  ...            0.352941    0.989093
5    0.692607             0.705426  ...            0.064516    1.465591
6    0.478599             0.542636  ...            0.626506    0.733128
7    0.653696             0.573643  ...            0.477612    0.756557
8    0.661479             0.720930  ...            0.244898    0.813768
9    0.778210             0.751938  ...            0.500000    0.978706
10   0.704280             0.713178  ...            0.250000    0.869681
11   0.715953             0.720930  ...            0.477612    1.021086
12   0.778210             0.767442  ...            0.476190    1.084335
13   0.754864             0.813953  ...            0.476190    1.061205
14   0.743191             0.697674  ...            0.474576    0.946122
15   0.743191             0.713178  ...            0.636364    1.585004
16   0.789883             0.767442  ...            0.413793    1.053433
17   0.770428             0.775194  ...            0.454545    1.166469
18   0.821012             0.821705  ...            0.470588    1.266022
19   0.727626             0.744186  ...            0.470588    1.189779
20   0.844358             0.844961  ...            0.500000    1.325312
21   0.817121             0.844961  ...            0.466667    1.235618
22   0.848249             0.790698  ...            0.578947    1.447906
23   0.809339             0.883721  ...            0.150000    1.302940
24   0.844358             0.813953  ...            0.463768    1.348436
25   0.848249             0.891473  ...            0.483871    1.337604
26   0.863813             0.844961  ...            0.466667    1.369363
27   0.859922             0.875969  ...            0.484848    1.497402
28   0.863813             0.875969  ...            0.385965    1.421115
29   0.832685             0.798450  ...            0.592593    1.706245
30   0.863813             0.891473  ...            0.476190    1.420495
31   0.797665             0.821705  ...            0.385965    1.273982
32   0.852140             0.829457  ...            0.477612    1.468592
33   0.797665             0.782946  ...            0.564103    1.665378
34   0.715953             0.782946  ...            0.542857    1.241564
35   0.801556             0.790698  ...            0.392857    1.123901
36   0.871595             0.837209  ...            0.466667    1.364715
37   0.867704             0.868217  ...            0.466667    1.418281
38   0.906615             0.906977  ...            0.466667    1.505292
39   0.867704             0.860465  ...            0.514286    1.631179
40   0.871595             0.899225  ...            0.413793    1.515317
41   0.883268             0.837209  ...            0.466667    1.526363
42   0.910506             0.899225  ...            0.461538    1.650033
43   0.805447             0.852713  ...            0.392857    1.464744
44   0.821012             0.806202  ...            0.545455    1.800943
45   0.894942             0.891473  ...            0.521739    1.599919
46   0.879377             0.875969  ...            0.468750    1.564624
47   0.813230             0.821705  ...            0.468750    1.483380
48   0.933852             0.922481  ...            0.500000    1.596315
49   0.894942             0.914729  ...            0.440678    1.549854

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0   0.79661            0.689655                  0.9      0.769231
TestLoader Losses 0.5055489388562865
@@@@ individuo =  8 [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.11817163662579326]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7966101694915254
verifyEntry ([4], [2], [1, 7], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=128, bias=True)
  (1): ReLU()
  (2): Linear(in_features=128, out_features=128, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.42282557555718114, inplace=False)
  (5): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.70 and acc: 48.33%
2299.48 total seconds elapsed. 114.97 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.494163             0.325581  ...            0.650000    0.697711
1    0.607004             0.852713  ...            0.280000    0.700665
2    0.599222             0.565891  ...            0.142857    0.704401
3    0.607004             0.666667  ...            0.095238    0.718088
4    0.595331             0.426357  ...            0.620690    0.733865
5    0.680934             0.751938  ...            0.424242    0.729718
6    0.708171             0.674419  ...            0.372881    0.738358
7    0.657588             0.705426  ...            0.357143    0.753336
8    0.727626             0.666667  ...            0.623377    0.783306
9    0.704280             0.713178  ...            0.451613    0.780501
10   0.688716             0.728682  ...            0.313725    0.798534
11   0.595331             0.627907  ...            0.100000    0.832789
12   0.696498             0.651163  ...            0.535211    0.820893
13   0.739300             0.705426  ...            0.385965    0.832189
14   0.770428             0.767442  ...            0.575342    0.869932
15   0.766537             0.736434  ...            0.617284    0.960435
16   0.766537             0.852713  ...            0.357143    0.869218
17   0.719844             0.744186  ...            0.291667    0.905230
18   0.762646             0.767442  ...            0.468750    0.885183
19   0.785992             0.759690  ...            0.607595    1.017212

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.661017                 1.0             0.333333       0.74359
TestLoader Losses 0.5740311635752856
@@@@ individuo =  4 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.11817163662579326]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.6610169491525424
result (0, 0.7288135593220338)
result (1, 0.7288135593220338)
result (2, 0.7288135593220338)
result (3, 0.6610169491525424)
result (4, 0.6610169491525424)
result (5, 0.7796610169491526)
result (6, 0.4915254237288136)
result (7, 0.7457627118644068)
result (8, 0.7966101694915254)
result (9, 0.4915254237288136)


 Saving new generated items of geração  5

individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([0, 0.11817163662579326])
 list([1, 7]) list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.11817163662579326]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([0, 0.11817163662579326])
 list([1, 7]) list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.11817163662579326]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 7], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.11817163662579326]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 7], [1, 7], [1, 0.42282557555718114]) 


individuo [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.11817163662579326]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114]) 


individuo [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([1, 0.43531701384079674])
 list([1, 7]) list([1, 0.42282557555718114])]  key  ([3], [5], [1, 7], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([1, 0.43531701384079674])
 list([1, 7]) list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114]) 


individuo [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.11817163662579326]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([3], [5], [1, 10]) 


individuo [list([3]) list([5]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([0, 0.11817163662579326])
 list([1, 7]) list([1, 0.42282557555718114])]  key  ([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114]) 



@@@@ Reinsercao

cacheStore =  {'([4], [3], [1, 5], [1, 0.1262070664185572], [1, 5])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.847457627118644, '([5], [4], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [2], [1, 3], [1, 4], [1, 4])': 0.7288135593220338, '([2], [1], [1, 9], [1, 0.17065736910750998], [1, 11], [1, 0.3197351493711345], [1, 11], [1, 0.5177330618879615], [1, 9], [1, 3], [1, 0.27610931992185345])': 0.5084745762711864, '([3], [5], [1, 8], [1, 10])': 0.7457627118644068, '([2], [6], [1, 8])': 0.7796610169491526, '([1], [4], [1, 5], [1, 12])': 0.5084745762711864, '([1], [4], [1, 4], [1, 0.5131789330011404])': 0.4915254237288136, '([1], [6], [1, 5], [1, 7], [1, 0.06254698615663809])': 0.5084745762711864, '([4], [2], [1, 3], [1, 12])': 0.7966101694915254, '([3], [5], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4])': 0.8135593220338984, '([5], [4], [1, 8], [1, 10])': 0.8305084745762712, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.2574753409377971], [1, 4], [1, 4])': 0.6440677966101694, '([4], [2], [1, 3], [1, 5])': 0.7796610169491526, '([4], [3], [1, 12])': 0.7627118644067796, '([3], [5])': 0.8305084745762712, '([3], [5], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.8135593220338984, '([4], [2], [1, 7], [1, 0.12676812206472354])': 0.8135593220338984, '([4], [2], [1, 3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.6610169491525424, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.12676812206472354])': 0.864406779661017, '([4], [3], [1, 7], [1, 0.12676812206472354])': 0.7966101694915254, '([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.8135593220338984, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([4], [2])': 0.7288135593220338, '([3], [5], [1, 7])': 0.8305084745762712, '([4], [2], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 7])': 0.7627118644067796, '([3], [5], [1, 7], [1, 0.5950958103579727], [1, 7], [1, 0.42282557555718114])': 0.7796610169491526, '([4], [2], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.6949152542372882, '([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 10])': 0.7288135593220338, '([3], [5], [1, 7], [1, 0.5950958103579727], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.4915254237288136, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])': 0.7457627118644068, '([4], [2], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674])': 0.6440677966101694, '([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114])': 0.7796610169491526, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])': 0.7288135593220338, '([4], [2], [1, 5], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.7288135593220338, '([4], [2], [1, 7], [1, 7], [1, 0.42282557555718114])': 0.6610169491525424, '([3], [5], [1, 7], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([3], [5], [1, 10])': 0.7966101694915254, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136}


 $$$$$$$$ Geração  6
population =  [[list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.5446961484005021]) list([1, 6])
  list([1, 0.43531701384079674]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.5465119394359016]) list([0, 10])
  list([0, 0.11817163662579326]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.11817163662579326]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.5446961484005021]) list([1, 6])
  list([1, 0.43531701384079674]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.5446961484005021]) list([1, 6])
  list([0, 0.11817163662579326]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.11817163662579326]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.5446961484005021]) list([1, 6])
  list([0, 0.11817163662579326]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.11817163662579326]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.11817163662579326]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.5446961484005021]) list([1, 6])
  list([1, 0.43531701384079674]) list([1, 7])
  list([1, 0.42282557555718114])]]
populationFitness =  [0.86440678 0.79661017 0.77966102 0.74576271 0.72881356 0.72881356
 0.72881356 0.66101695 0.66101695 0.49152542]
bestParent, bestParentFitness [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.5446961484005021]) list([1, 6]) list([1, 0.43531701384079674])
 list([1, 7]) list([1, 0.42282557555718114])] 0.864406779661017


@@@@ Selecao
indexParent 2
indexParent 7
indexParent 4
indexParent 0
indexParent 1
indexParent 2
indexParent 1
indexParent 1
indexParent 2
indexParent 4


@@@@ Crossover
crossoverPoint 5
not changing individuals
crossoverPoint 9
crossoverPoint 1
crossoverPoint 9


@@@@ Mutacao
Individuos para mutacao [5, 1]
@@@ mutated [0, 0.09643501348207106]
@@@ mutated [0, 0.27251493520639586]


@@@@ Calculando fitness
verifyEntry ([3], [5], [1, 7])

achei cache 0.8305084745762712  individuo =  7 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.09643501348207106]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.8305084745762712
verifyEntry ([4], [2], [1, 7], [1, 7], [1, 0.42282557555718114])

achei cache 0.6610169491525424  individuo =  5 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.6610169491525424
verifyEntry ([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114])

achei cache 0.7796610169491526  individuo =  0 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7796610169491526
verifyEntry ([3], [5], [1, 10])

achei cache 0.7966101694915254  individuo =  3 [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.09643501348207106]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7966101694915254
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])

achei cache 0.7288135593220338  individuo =  9 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.27251493520639586]) list([1, 6])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7288135593220338
verifyEntry ([3], [5], [1, 10], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=1024, bias=True)
  (1): ReLU()
  (2): Linear(in_features=1024, out_features=128, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.42282557555718114, inplace=False)
  (5): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 1 with loss: 0.70 and acc: 48.33%
2962.50 total seconds elapsed. 59.25 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.439689             0.395349  ...            0.000000    0.698306
1    0.529183             0.519380  ...            0.650602    0.696153
2    0.529183             0.542636  ...            0.000000    0.700507
3    0.568093             0.286822  ...            0.641026    0.714343
4    0.583658             0.643411  ...            0.611765    0.748371
5    0.645914             0.651163  ...            0.666667    1.047463
6    0.700389             0.682171  ...            0.387097    0.914930
7    0.719844             0.728682  ...            0.260870    0.954948
8    0.712062             0.720930  ...            0.582278    0.891439
9    0.778210             0.744186  ...            0.586667    1.104516
10   0.750973             0.798450  ...            0.592593    1.065900
11   0.743191             0.744186  ...            0.459016    1.072672
12   0.754864             0.751938  ...            0.451613    0.858109
13   0.758755             0.821705  ...            0.609756    1.155891
14   0.856031             0.883721  ...            0.466667    1.264098
15   0.793774             0.806202  ...            0.521739    1.158521
16   0.824903             0.829457  ...            0.491803    1.244083
17   0.805447             0.821705  ...            0.491803    1.253455
18   0.863813             0.875969  ...            0.597403    1.396215
19   0.793774             0.798450  ...            0.440678    1.065081
20   0.836576             0.875969  ...            0.162162    1.265375
21   0.824903             0.775194  ...            0.492754    1.294167
22   0.797665             0.813953  ...            0.476190    1.199216
23   0.836576             0.829457  ...            0.500000    1.201755
24   0.852140             0.852713  ...            0.540541    1.572349
25   0.875486             0.906977  ...            0.483871    1.254518
26   0.836576             0.860465  ...            0.459016    1.115337
27   0.817121             0.844961  ...            0.448276    1.249657
28   0.848249             0.837209  ...            0.578947    1.304415
29   0.840467             0.852713  ...            0.440678    1.230767
30   0.863813             0.844961  ...            0.483871    1.429568
31   0.883268             0.891473  ...            0.477612    1.409934
32   0.902724             0.937984  ...            0.413793    1.424731
33   0.727626             0.651163  ...            0.466667    0.866237
34   0.821012             0.875969  ...            0.448276    1.239424
35   0.856031             0.868217  ...            0.459016    1.295980
36   0.840467             0.868217  ...            0.500000    1.206631
37   0.871595             0.875969  ...            0.477612    1.347773
38   0.863813             0.837209  ...            0.563380    1.478969
39   0.863813             0.899225  ...            0.227273    1.450437
40   0.828794             0.821705  ...            0.500000    1.058533
41   0.894942             0.906977  ...            0.492308    1.540774
42   0.696498             0.798450  ...            0.597403    0.913234
43   0.824903             0.806202  ...            0.440678    1.216891
44   0.871595             0.852713  ...            0.619048    1.711090
45   0.809339             0.860465  ...            0.428571    1.183041
46   0.844358             0.868217  ...            0.212766    1.408291
47   0.879377             0.899225  ...            0.440678    1.268368
48   0.891051             0.906977  ...            0.492308    1.506700
49   0.875486             0.899225  ...            0.491803    1.600786

[50 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.762712            0.758621             0.766667      0.758621
TestLoader Losses 0.5044058429992805
@@@@ individuo =  2 [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7627118644067796
verifyEntry ([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114])

achei cache 0.7796610169491526  individuo =  4 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7796610169491526
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])

achei cache 0.7288135593220338  individuo =  1 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.27251493520639586]) list([1, 6])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7288135593220338
verifyEntry ([3], [5], [1, 10])

achei cache 0.7966101694915254  individuo =  8 [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.09643501348207106]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7966101694915254
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])

achei cache 0.7457627118644068  individuo =  6 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.27251493520639586]) list([1, 6])
 list([1, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7457627118644068
result (0, 0.7796610169491526)
result (1, 0.7288135593220338)
result (2, 0.7627118644067796)
result (3, 0.7966101694915254)
result (4, 0.7796610169491526)
result (5, 0.6610169491525424)
result (6, 0.7457627118644068)
result (7, 0.8305084745762712)
result (8, 0.7966101694915254)
result (9, 0.7288135593220338)


 Saving new generated items of geração  6

individuo [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.27251493520639586]) list([1, 6])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114]) 


individuo [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([3], [5], [1, 10], [1, 7], [1, 0.42282557555718114]) 


individuo [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.09643501348207106]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([3], [5], [1, 10]) 


individuo [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 7], [1, 7], [1, 0.42282557555718114]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.27251493520639586]) list([1, 6])
 list([1, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114]) 


individuo [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.09643501348207106]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([3], [5], [1, 7]) 


individuo [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
 list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
 list([1, 0.5465119394359016]) list([0, 10])
 list([0, 0.09643501348207106]) list([0, 3])
 list([0, 0.18389479625169752])]  key  ([3], [5], [1, 10]) 


individuo [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.27251493520639586]) list([1, 6])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])]  key  ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114]) 



@@@@ Reinsercao

cacheStore =  {'([4], [3], [1, 5], [1, 0.1262070664185572], [1, 5])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.847457627118644, '([5], [4], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [2], [1, 3], [1, 4], [1, 4])': 0.7288135593220338, '([2], [1], [1, 9], [1, 0.17065736910750998], [1, 11], [1, 0.3197351493711345], [1, 11], [1, 0.5177330618879615], [1, 9], [1, 3], [1, 0.27610931992185345])': 0.5084745762711864, '([3], [5], [1, 8], [1, 10])': 0.7457627118644068, '([2], [6], [1, 8])': 0.7796610169491526, '([1], [4], [1, 5], [1, 12])': 0.5084745762711864, '([1], [4], [1, 4], [1, 0.5131789330011404])': 0.4915254237288136, '([1], [6], [1, 5], [1, 7], [1, 0.06254698615663809])': 0.5084745762711864, '([4], [2], [1, 3], [1, 12])': 0.7966101694915254, '([3], [5], [1, 7], [1, 0.12676812206472354])': 0.7796610169491526, '([4], [3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4])': 0.8135593220338984, '([5], [4], [1, 8], [1, 10])': 0.8305084745762712, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.2574753409377971], [1, 4], [1, 4])': 0.6440677966101694, '([4], [2], [1, 3], [1, 5])': 0.7796610169491526, '([4], [3], [1, 12])': 0.7627118644067796, '([3], [5])': 0.8305084745762712, '([3], [5], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.8135593220338984, '([4], [2], [1, 7], [1, 0.12676812206472354])': 0.8135593220338984, '([4], [2], [1, 3], [1, 5], [1, 0.1262070664185572], [1, 4], [1, 4], [1, 0.3278614521834228])': 0.6610169491525424, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.12676812206472354])': 0.864406779661017, '([4], [3], [1, 7], [1, 0.12676812206472354])': 0.7966101694915254, '([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.8135593220338984, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([4], [2])': 0.7288135593220338, '([3], [5], [1, 7])': 0.8305084745762712, '([4], [2], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 7])': 0.7627118644067796, '([3], [5], [1, 7], [1, 0.5950958103579727], [1, 7], [1, 0.42282557555718114])': 0.7796610169491526, '([4], [2], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.6949152542372882, '([5], [4], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 10])': 0.7288135593220338, '([3], [5], [1, 7], [1, 0.5950958103579727], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12])': 0.4915254237288136, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 12], [1, 7], [1, 0.42282557555718114])': 0.7966101694915254, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])': 0.7457627118644068, '([4], [2], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 0.43531701384079674])': 0.6440677966101694, '([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114])': 0.7796610169491526, '([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])': 0.7288135593220338, '([4], [2], [1, 5], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.7288135593220338, '([4], [2], [1, 7], [1, 7], [1, 0.42282557555718114])': 0.6610169491525424, '([3], [5], [1, 7], [1, 11], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([3], [5], [1, 10])': 0.7966101694915254, '([3], [5], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 6], [1, 7], [1, 0.42282557555718114])': 0.4915254237288136, '([3], [5], [1, 10], [1, 7], [1, 0.42282557555718114])': 0.7627118644067796}


 $$$$$$$$ Geração  7
population =  [[list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.27251493520639586]) list([1, 6])
  list([1, 0.43531701384079674]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.09643501348207106]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.5465119394359016]) list([0, 10])
  list([0, 0.09643501348207106]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.5465119394359016]) list([0, 10])
  list([0, 0.09643501348207106]) list([0, 3])
  list([0, 0.18389479625169752])]
 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.09643501348207106]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
  list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
  list([1, 0.38275251356251844]) list([0, 10])
  list([0, 0.09643501348207106]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([3]) list([5]) list([0, 11]) list([1, 0.5950958103579727])
  list([1, 10]) list([0, 0.48319691862799363]) list([0, 8])
  list([1, 0.5465119394359016]) list([0, 10])
  list([0, 0.09643501348207106]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.27251493520639586]) list([1, 6])
  list([1, 0.43531701384079674]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.27251493520639586]) list([1, 6])
  list([0, 0.09643501348207106]) list([1, 7])
  list([1, 0.42282557555718114])]
 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
  list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
  list([0, 0.27251493520639586]) list([1, 6])
  list([0, 0.09643501348207106]) list([1, 7])
  list([1, 0.42282557555718114])]]
populationFitness =  [0.86440678 0.83050847 0.79661017 0.79661017 0.77966102 0.77966102
 0.76271186 0.74576271 0.72881356 0.72881356]
bestParent, bestParentFitness [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([0, 0.27251493520639586]) list([1, 6])
 list([1, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])] 0.864406779661017


@@@@ Selecao
indexParent 0
indexParent 3
indexParent 0
indexParent 5
indexParent 1
indexParent 0
indexParent 3
indexParent 0
indexParent 5
indexParent 3


@@@@ Crossover
crossoverPoint 10
crossoverPoint 1
crossoverPoint 2
crossoverPoint 8
crossoverPoint 2


@@@@ Mutacao
Individuos para mutacao [5, 0]
@@@ mutated [1, 11]
@@@ mutated [1, 0.27251493520639586]


@@@@ Calculando fitness
verifyEntry ([3], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.27251493520639586], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Dropout(p=0.27251493520639586, inplace=False)
  (8): Linear(in_features=2048, out_features=64, bias=True)
  (9): ReLU()
  (10): Dropout(p=0.43531701384079674, inplace=False)
  (11): Linear(in_features=64, out_features=128, bias=True)
  (12): ReLU()
  (13): Dropout(p=0.42282557555718114, inplace=False)
  (14): Linear(in_features=128, out_features=2, bias=True)
)

Best epoch: 17 with loss: 0.69 and acc: 50.00%
3439.51 total seconds elapsed. 171.98 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.560311             0.751938  ...            0.000000    0.693351
1    0.447471             0.682171  ...            0.666667    0.694388
2    0.486381             0.689922  ...            0.000000    0.693211
3    0.459144             0.596899  ...            0.666667    0.693309
4    0.494163             0.697674  ...            0.000000    0.693149
5    0.486381             0.387597  ...            0.666667    0.693300
6    0.478599             0.798450  ...            0.666667    0.694276
7    0.501946             0.961240  ...            0.666667    0.693591
8    0.509728             0.961240  ...            0.666667    0.693642
9    0.474708             0.798450  ...            0.666667    0.693419
10   0.521401             0.860465  ...            0.666667    0.693237
11   0.389105             0.457364  ...            0.666667    0.693302
12   0.517510             0.534884  ...            0.000000    0.693150
13   0.501946             0.627907  ...            0.666667    0.693347
14   0.498054             0.728682  ...            0.666667    0.693328
15   0.466926             0.767442  ...            0.666667    0.693244
16   0.490272             0.534884  ...            0.000000    0.693148
17   0.525292             0.465116  ...            0.000000    0.693147
18   0.501946             0.635659  ...            0.666667    0.693207
19   0.463035             0.744186  ...            0.666667    0.693166

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.491525                 1.0                  0.0      0.659091
TestLoader Losses 0.6932700559244318
@@@@ individuo =  6 [list([3]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([1, 0.27251493520639586]) list([1, 6])
 list([1, 0.43531701384079674]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.4915254237288136
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.27251493520639586], [1, 6], [1, 0.43531701384079674])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Dropout(p=0.27251493520639586, inplace=False)
  (8): Linear(in_features=2048, out_features=64, bias=True)
  (9): ReLU()
  (10): Dropout(p=0.43531701384079674, inplace=False)
  (11): Linear(in_features=64, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.69 and acc: 43.33%
3429.80 total seconds elapsed. 171.49 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.501946             1.000000  ...            0.666667    0.694033
1    0.556420             0.294574  ...            0.589744    0.694141
2    0.587549             0.519380  ...            0.666667    0.699188
3    0.614786             0.682171  ...            0.625000    0.711197
4    0.603113             0.705426  ...            0.666667    0.739481
5    0.603113             0.643411  ...            0.575342    0.730471
6    0.692607             0.674419  ...            0.607595    0.801106
7    0.712062             0.775194  ...            0.555556    0.828212
8    0.727626             0.744186  ...            0.492308    0.873003
9    0.747082             0.782946  ...            0.582278    0.992197
10   0.743191             0.751938  ...            0.419355    0.982137
11   0.793774             0.829457  ...            0.527778    1.012202
12   0.766537             0.806202  ...            0.468750    1.067778
13   0.774319             0.782946  ...            0.527778    1.077314
14   0.801556             0.829457  ...            0.492308    1.133067
15   0.785992             0.759690  ...            0.535211    1.103922
16   0.832685             0.875969  ...            0.468750    1.270552
17   0.852140             0.868217  ...            0.626506    1.415373
18   0.832685             0.829457  ...            0.556962    1.329975
19   0.824903             0.868217  ...            0.527778    1.241786

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.779661            0.931034             0.633333       0.80597
TestLoader Losses 0.4827828685105857
@@@@ individuo =  0 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([1, 0.27251493520639586]) list([1, 6])
 list([1, 0.43531701384079674]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7796610169491526
verifyEntry ([4], [2], [1, 7])

achei cache 0.7627118644067796  individuo =  7 [list([4]) list([2]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.09643501348207106]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.7627118644067796
verifyEntry ([4], [2], [1, 5], [1, 10], [1, 0.1857731567558439], [1, 11], [1, 0.27251493520639586])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=32, bias=True)
  (1): ReLU()
  (2): Linear(in_features=32, out_features=1024, bias=True)
  (3): ReLU()
  (4): Dropout(p=0.1857731567558439, inplace=False)
  (5): Linear(in_features=1024, out_features=2048, bias=True)
  (6): ReLU()
  (7): Dropout(p=0.27251493520639586, inplace=False)
  (8): Linear(in_features=2048, out_features=2, bias=True)
)

Best epoch: 0 with loss: 0.69 and acc: 46.67%
3426.80 total seconds elapsed. 171.34 seconds per epoch.

Historico treinamento e validação 
     train_acc  train_sensitividade  ...  validation_f1Score  valid_loss
0    0.498054             0.542636  ...            0.658537    0.694114
1    0.466926             0.488372  ...            0.064516    0.695062
2    0.536965             0.379845  ...            0.674157    0.702211
3    0.536965             0.643411  ...            0.658537    0.715780
4    0.645914             0.480620  ...            0.666667    0.709280
5    0.731518             0.790698  ...            0.437500    0.775957
6    0.731518             0.736434  ...            0.613333    0.919360
7    0.758755             0.813953  ...            0.613333    1.001325
8    0.747082             0.767442  ...            0.379310    0.999708
9    0.754864             0.736434  ...            0.634146    1.061998
10   0.673152             0.744186  ...            0.615385    0.918850
11   0.778210             0.798450  ...            0.437500    1.022468
12   0.754864             0.790698  ...            0.586667    1.081934
13   0.735409             0.782946  ...            0.500000    1.044710
14   0.848249             0.860465  ...            0.477612    1.140442
15   0.836576             0.868217  ...            0.563380    1.261919
16   0.789883             0.837209  ...            0.477612    1.171290
17   0.731518             0.720930  ...            0.451613    1.096398
18   0.821012             0.844961  ...            0.406780    1.210603
19   0.809339             0.821705  ...            0.589744    1.257186

[20 rows x 10 columns]

Testing result
    test_acc  test_sensitividade  test_especificidade  test_f1Score
0  0.711864            0.931034                  0.5      0.760563
TestLoader Losses 0.576306411775492
@@@@ individuo =  8 [list([4]) list([2]) list([1, 5]) list([0, 0.16625800380687808])
 list([1, 10]) list([1, 0.1857731567558439]) list([1, 11])
 list([1, 0.27251493520639586]) list([0, 10])
 list([0, 0.09643501348207106]) list([0, 3])
 list([0, 0.18389479625169752])] 
 fitness =  0.711864406779661
verifyEntry ([3], [5], [1, 7], [1, 7], [1, 0.42282557555718114])

achei cache 0.7796610169491526  individuo =  9 [list([3]) list([5]) list([1, 7]) list([0, 0.09768904831161847])
 list([0, 9]) list([0, 0.5425670915470017]) list([0, 11])
 list([1, 0.38275251356251844]) list([0, 10])
 list([0, 0.09643501348207106]) list([1, 7])
 list([1, 0.42282557555718114])] 
 fitness =  0.7796610169491526
result (0, 0.7796610169491526)
verifyEntry ([3], [5], [1, 11], [1, 0.5950958103579727], [1, 10], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=2048, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.5950958103579727, inplace=False)
  (3): Linear(in_features=2048, out_features=1024, bias=True)
  (4): ReLU()
  (5): Linear(in_features=1024, out_features=128, bias=True)
  (6): ReLU()
  (7): Dropout(p=0.42282557555718114, inplace=False)
  (8): Linear(in_features=128, out_features=2, bias=True)
)
verifyEntry ([3], [5], [1, 11], [1, 0.5950958103579727], [1, 10], [1, 6], [1, 0.43531701384079674], [1, 7], [1, 0.42282557555718114])
custom fc Sequential(
  (0): Linear(in_features=2048, out_features=2048, bias=True)
  (1): ReLU()
  (2): Dropout(p=0.5950958103579727, inplace=False)
  (3): Linear(in_features=2048, out_features=1024, bias=True)
  (4): ReLU()
  (5): Linear(in_features=1024, out_features=64, bias=True)
  (6): ReLU()
  (7): Dropout(p=0.43531701384079674, inplace=False)
  (8): Linear(in_features=64, out_features=128, bias=True)
  (9): ReLU()
  (10): Dropout(p=0.42282557555718114, inplace=False)
  (11): Linear(in_features=128, out_features=2, bias=True)
)
